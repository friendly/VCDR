% template for a new chapter
<<echo=FALSE, purl=FALSE>>=
source("Rprofile.R")
knitrSet("ch11")
.locals$ch11 <- NULL
.pkgs$ch11 <- NULL
library(ggplot2)
library(vcdExtra)
theme_set(theme_bw())  # set default ggplot theme
@

\chapter{Generalized Linear Models for Count Data}\label{ch:glm}
\input{front/vtoc11}		% visual table of contents

\chapterprelude{
Generalized linear models extend the familiar linear models of
regression and ANOVA to
include counted data, frequencies, and other data for which the
assumptions of independent normal errors are not reasonable.
We rely on the analogies between ordinary and generalized linear
models (GLMs) to develop visualization methods to explore the data,
display the fitted relationships, and check model assumptions.
The main focus of this chapter is on models for count data.
}
% \minitoc
% \clearpage

\epigraph{In one word, to draw the rule from experience, one must generalize; this is a necessity that imposes itself on the most circumspect observer.}
{Henri Poincar\'e, \emph{The Value of Science: Essential Writings of Henri Poincar\'e}}

In the modern history of statistics, most developments occur incrementally, with
small additions to existing models and theory that extend their range
and applicability to new problems and data.  Occasionally, there is
a major synthesis that unites a wide class of existing methods in a
general framework and provides opportunities for far greater growth.

\ixon{generalized linear model}

A prime example is the theory of generalized linear models, introduced
originally by \citet{NelderWedderburn:72}, that extended the familiar
(classical) linear models for regression and ANOVA to include related
models, such as logistic regression and logit models (described in \chref{ch:logistic})
and \loglin models (described in \chref{ch:loglin}),
and other variations, as ``families'' within a single general system.

This approach has proved attractive because it:
\begin{seriate}
 \item integrates many familiar statistical models in a general theory where they are
 just special cases;
 \item provides the basis for extending these and developing new models within the
 same or similar framework;
 \item simplifies the implementation of these models in software, since the same
 algorithm can be used for estimation, inference, and assessing model adequacy
 for all generalized linear models.
\end{seriate}

\secref{glm:components} gives a brief sketch of the GLM framework.
The focus of this book is on visualization methods for categorical
data, and the two important topics concern models and methods for binomial response data
and for count data.  The first of these
was described extensively in
\chref{ch:logistic},
with extensions to multinomial
data (\chref{ch:polytomous}),
% and multivariate responses
and there is little to add here, except for changes
in notation.

\ix{generalized linear model!count data}
\ix{count data}
GLM models for count data, however, provide the opportunity to extend
the scope of these methods beyond what was covered in \chref{ch:loglin},
and this topic is introduced in \secref{sec:glm-count}.
Extensions to the 
GLM framework also provide the opportunity to deal with common problems
of overdispersion (\secref{sec:glm-overdisp}) and an overabundance of
zero counts (\secref{sec:glm-zeros}), giving some new models and
visualization methods that help to understand such data in greater detail.
These are illustrated with two case studies in \secref{sec:glm-casestudies}.
\secref{sec:glm-diag} illustrates other graphical methods for diagnostic
model checking, some of which were introduced in earlier chapters.
Finally, \secref{sec:glm-multiv} outlines some simple extensions of these
models to handle multivariate responses.


\section{Components of generalized linear models}\label{glm:components}
\ixon{generalized linear model!components}
\ix{regression}
The motivation for the \textbf{generalized linear model} (GLM) and its structure are most
easily seen by considering the classical linear model,
\begin{equation*}
y_i = \vec{x}_i\trans \vec{\beta} + \epsilon_i \comma
\end{equation*}
where
$y_i$ is the response variable for case $i, i=1, \dots n$,
$\vec{x}_i$ is the vector of explanatory variables or regressors,
$\vec{\beta}$ is the vector of model parameters, and the
$\epsilon_i$ are random errors.
In the classical linear model, the $\epsilon_i$ are assumed to
\begin{seriate}
  \item have constant variance, $\sigma^2_\epsilon$,
  \item follow a normal (Gaussian) distribution (conditional on
    $\vec{x}_i$), and
  \item be independent across observations.
\end{seriate}

\ix{hierarchical models}
\ix{clustered data}
\ix{correlated data}
Thus, \citet{NelderWedderburn:72} generalized this Gaussian linear model to
consist of the following three components, by relaxing assumptions (a) and (b) above:%
\footnote{The remaining assumption of independent observations is relaxed in
\term{generalized linear mixed models} (GLMMs), in which random effects to account for non-independence
are added to the linear predictor.
This allows the modeling of correlated (responses of family members), clustered (residents in
different communities),
or hierarchical data
(patients within hospitals within regions). See: \citet{McCullochNeuhaus:2005} and \citet{Hedeker:2005}
%\TODO{other references?}
}

\begin{description}
  \item[random component:] The conditional distribution of the $y_i \given \vec{x}_i$,
  with mean $\E (y_i) = \mu_i$. Under classical assumptions,
  this is independent, normal with constant variance $\sigma^2$, i.e.,
  $ y_i \stackrel{\textrm{iid}}{\sim} N (\mu_i, \sigma^2)$.
  In the GLM, the probability distribution of the $y_i$ can be any member of the
  \term{exponential family}, including the normal, Poisson, binomial, gamma,
  and others. Subsequent work has extended this framework to include
  multinomial distributions and some non-exponential families such as the
  negative binomial distribution.

\ix{distributions!normal}
\ix{distributions!Poisson}
\ix{distributions!binomial}
\ix{distributions!gamma}

  \item[systematic component:] The idea that the predicted value of $y_i$ itself
  is a linear
  combination of the regressors is replaced by that of a \term{linear predictor},
  $\eta$, that captures this aspect of linear models,
\begin{equation*}
\eta_i = \vec{x}_i\trans \vec{\beta} \period
\end{equation*}


  \item[link function:] The connection between the mean of the response, $\mu_i$,
  and the linear predictor, $\eta_i$, is specified by the \term{link function},
  $g(\bullet)$, giving
\begin{equation*}
g(\mu_i) = \eta_i = \vec{x}_i\trans \vec{\beta} \period
\end{equation*}
  The link function $g(\bullet)$ must be both \emph{smooth} and \emph{monotonic}, meaning that
  it is one-to-one, so an inverse transformation, $g^{-1}(\bullet)$ exists,
\begin{equation*}
\mu_i = g^{-1}(\eta_i) = g^{-1}(\vec{x}_i\trans \vec{\beta}) \comma
\end{equation*}
  which allows us to obtain and plot the predicted values on their original scale.  The link function
  captures the familiar idea that linear models are often estimated with a transformation
  of the response, such as $\log(y_i)$ for a frequency variable or $\logit(y_i)$
  for a binomial variable.  The inverse function $g^{-1}(\bullet)$
  is also called the \term{mean function}.
\end{description}

\input{ch11/tab/link-funcs}

\ix{binomial samples}
Some commonly used link functions are shown in \tabref{tab:link-funcs}.
Some of these link functions have restrictions on the range of $y_i$
to which they can be applied.  For example, the square-root and log links
apply only to non-negative and
positive values, respectively.
The last four link functions in this
table are for binomial data, where $y_i$ represents the observed proportion
of successes in $n_i$ independent trials, and thus the mean $\mu_i$
represents the probability of success (symbolized by $\pi_i$ in \chref{ch:logistic}).
Binary data are the special case where $n_i=1$.
\ixoff{generalized linear model!components}

\subsection{Variance functions}
\ixon{generalized linear model!variance functions}
The GLM has the additional property that, for distributions in the exponential family,
the conditional variance of $y_i \given \eta_i$ is a known function, $\V (\mu_i)$,
of the mean and possibly one other parameter called the \term{scale parameter} or
\term{dispersion parameter}, $\phi$. Some commonly used distributions in the
exponential family and their variance functions are shown in \tabref{tab:exp-families}.

\input{ch11/tab/exp-families}

\begin{itemize}
\item In the classical Gaussian linear model, the conditional variance is constant,
$\phi = \sigma^2_\epsilon$.

\ix{Poisson distribution}
\ix{distributions!Poisson}
\item In the Poisson family, $\V (\mu_i) = \mu_i$
and the dispersion parameter is fixed at $\phi = 1$.
In practice, it is common for count data to exhibit \term{overdispersion},
meaning that $\V (\mu_i) > \mu_i$.  One way to correct for this is to extend
the GLM to allow the dispersion parameter to be estimated from the data,
giving what is called the \term{quasi-Poisson} family, with $\V (\mu_i) = \widehat{\phi} \mu_i$.

\item Similarly, for binomial data, the variance function is $\V (\mu_i) = \mu_i (1-\mu_i) / n_i$,
with $\phi$ fixed at 1.
Overdispersion often results from failures of the assumptions of the binomial model:
supposedly independent observations may be correlated or clustered and the probability
of success may not be constant, or vary with unmeasured or unmodeled variables.

\ix{gamma distribution}
\ix{distributions!gamma}

\item The gamma and inverse-Gaussian families are distributions useful for modeling a continuous
and positive response variable with no upper bound (e.g., reaction time). They both have the
property that conditional variance increases with the mean, and for the inverse-Gaussian,
variance increases at a faster rate.  Their dispersion parameters $\phi$ are simple functions
of their intrinsic ``shape'' parameters, indicated as $\nu$ in the table.

\end{itemize}

The important points from this discussion are that the GLM together with the exponential
family of distributions:
\ix{dispersion parameter}
\ix{link function}
\begin{itemize}
 \item provide for simple linear relations between the response and the predictors
 via the link function and the linear predictor.
 \item allow a very flexible relationship between the mean and
 conditional variance to be specified in terms of a set of known families.
 \item incorporate a dispersion parameter $\phi$ that in some cases can be estimated
 or tested for departure from that entailed in a given family.
 \item have allowed further extensions of this framework outside the exponential family,
 ranging from simple adjustments for statistical inference (``quasi'' families,
 adjusted ``sandwich'' covariances) to separate modeling of the variance relation
 to the predictors.
\end{itemize}

Further details of generalized linear models are beyond the scope of this book, but
the interested reader should consult \citet[\S 15.3]{Fox:2008}
and \citet[Ch. 4]{Agresti:2013} for a comprehensive
treatment.
\ixoff{generalized linear model!variance functions}

\subsection{Hypothesis tests for coefficients}\label{sec:glm-hyptests}
\ixon{generalized linear model!hypothesis tests}
GLMs are fit using maximum likelihood estimation, and implemented in software using
an iterative algorithm known as \emph{iteratively weighted least squares}
that generalizes the least squares method for classical linear models.
This provides estimates $\vec{\widehat{\beta}}$ of the model coefficients
for the predictors in $\vec{x}$, as well as an estimated asymptotic
(large sample) variance matrix of $\vec{\widehat{\beta}}$, given by
\begin{equation}\label{eq:varbeta}
\V (\widehat{\vec{\beta}}) = \phi ( \mat{X}\trans  \mat{W} \mat{X} ) \comma
\end{equation}
where $\mat{W}$ is a diagonal matrix of weights computed in the final iteration.
In the standard Poisson GLM, the weight matrix is $\mat{W} = \diag (\widehat{\vec{\mu}})$
and $\phi=1$ is assumed.
\ix{distributions!Poisson}
\ix{Poisson distribution}

Asymptotic standard errors, $ \mathrm{se} (\widehat{\beta}_j)$,
for the coefficients are then the square roots of the
diagonal elements
% $ \sqrt{ \V (\widehat{\vec{\beta}})_{jj}}$,
of $\V (\widehat{\vec{\beta}})$, and tests of hypotheses regarding
an individual coefficient, e.g., $H_0 : \beta_j = 0$, can be carried out
using the Wald test statistic,
\ix{Wald test}
$z_j = \widehat{\beta}_j / \mathrm{se} (\widehat{\beta}_j)$.
When the null hypothesis is true, $z_j$ has a standard normal $\mathcal{N}(0,1)$
distribution, providing $p$-values for significance tests.%
\footnote{Wald tests are sometimes carried out using $z^2$, which has an equivalent
$\chi^2_1$ distribution with 1 degree of freedom.
}

\ix{hypothesis matrix}
More generally, we can test any \term{linear hypothesis}, of the form
$H_0 : \mat{L} \vec{\beta} = \vec{c}$, where $\mat{L}$ is a constant hypothesis matrix
of size $h \times p$ giving $h$ linear combinations of the coefficients,
to be tested for equality with the constants in $\vec{c}$, typically taken as $\vec{c}=\vec{0}$.
The test statistic is the Wald chi-square,
\begin{equation}\label{eq:waldchisq}
Z^2 = (\mat{L} \widehat{\vec{\beta}} - \vec{c})\trans \:
      [\mat{L} \V (\widehat{\vec{\beta}}) \mat{L}\trans]^{-1} \:
      (\mat{L} \widehat{\vec{\beta}} - \vec{c}) \comma
\end{equation}
\ix{dispersion parameter}
which has a $\chisq$ distribution on $h$ degrees of freedom.%
\footnote{When a dispersion parameter $\phi$ has been estimated from the data,
it is common to use an $F$-test, using the statistic $F = Z^2 / h$,
with $h$ and $n-p$ degrees of freedom.}

For example, to test the hypothesis
that all of
$\beta_1 = \beta_2 = \beta_3 =0$ in a model with three predictors, you can use
\begin{equation*}
\mat{L} = \left[
{\begin{array}{*{20}{c}}
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 &1
\end{array}}
\right] =
\left[
{\begin{array}{*{20}{c}}
{\vec{0}} & {\mat{I}}
\end{array}}
\right]
\comma
\quad\quad
\vec{c} = \left(
{\begin{array}{*{20}{c}}
0\\
0\\
0
\end{array}}
\right) \period
\end{equation*}
Similarly, to test the hypothesis that $\beta_1 = \beta_2$ in the same model,
you can use $\mat{L} = [0, 1, -1, 0]$ and $\vec{c} = [0]$.%
\footnote{Such a test is only sensible if the predictors $\vec{x_1}$ and $\vec{x_2}$
are on the same scale, so their coefficients are commensurable.}

In \R, such tests are most conveniently carried out using \func{linearHypothesis}
in the \Rpackage{car}, supporting \citet{fox+weisberg:2011}.  
The hypothesis matrix $\mat{L}$ can be supplied as a
numeric matrix, or more conveniently,
the hypothesis can be specified symbolically as a character vector
of the names of the coefficients involved in each row of $\mat{L}$.
For example, the first hypothesis test above could be specified using the vector
\code{c("x1=0", "x2=0", "x3=0")}, and the test of equality as
\code{"x1-x2=0"}.
\ixoff{generalized linear model!hypothesis tests}

\subsection{Goodness-of-fit tests}\label{sec:glm-goodfit}
\ixon{generalized linear model!goodness-of-fit}
\ix{goodness-of-fit}
The basic ideas for testing goodness-of-fit were discussed in \secref{sec:loglin-goodfit}
in connection with \loglin models for \ctabs.
As before, these assess the overall performance of a model in reproducing the data.
The commonly used measures include the Pearson chi-square and
\ix{likelihood ratio test}
\ix{deviance}
\LR deviance statistics, which can be seen as weighted sums of residuals.
We re-state these test statistics here in the wider context of the GLM.

Let $y_i, i=1, 2, \dots, n$ be the response and $\widehat{\mu}_i = g^{-1} (\vec{x}_i\trans \widehat{\vec{\beta}})$
the fitted mean using the estimated coefficients, having estimated variance
$\widehat{\omega}_i = \V(\widehat{\mu}_i\given \eta_i)$ as in \tabref{tab:exp-families}.
Then the normalized squared residual for observation $i$ is
$(y_i - \widehat{\mu}_i)^2 / \widehat{\omega}_i$, and the Pearson statistic is
\begin{equation}\label{eq:pearson}
X^2_P = \sum_{i=1}^n \frac{(y_i - \widehat{\mu}_i)^2}{\widehat{\omega}_i} \period
\end{equation}

\ix{count data}
In the GLM for count data, the main focus of this chapter, the Poisson family
sets $\omega = \mu$ with the dispersion parameter fixed at $\phi=1$.

The \term{residual deviance} statistic, as in logistic regression and \loglin models,
is defined as twice the difference between the maximum possible log-likelihood
for the \emph{saturated model} that fits perfectly and maximized log-likelihood
for the fitted model. The deviance can be defined as
\begin{equation*}
D (\vec{y}, \vec{\widehat{\mu}}) \equiv 2 [ \log_e
\mathcal{L}(\vec{y};\vec{y}) - \log_e
\mathcal{L}(\vec{y};\vec{\widehat{\mu}})] \period
\end{equation*}
For classical linear models under normality, the deviance is simply the residual sum of squares,
$\sum_i^n (y_i - \widehat{\mu}_i)$.  This has led to the deviance being taken in the GLM
framework as a generalization of the sum of squares used in ANOVA, and hence, an analogous
\term{analysis of deviance} to carry out tests for individual terms in GLMs, or to compare
nested models.

\ix{sequantial models}
In \R, \code{anova(mod)} for the \class{glm} object \code{mod}
gives \emph{sequential} (``Type I'') tests of successive terms in a model, while
\func{Anova} in the \Rpackage{car} gives the more generally useful
``Type II'' (and ``Type III'') \emph{partial} tests, that assess the additional
contribution of each term above all others, taking marginality into account.

For Poisson models with a log link giving $\vec{\mu} = \exp(\vec{x}\trans \vec{\beta})$, the deviance takes the form%
\footnote{In the context of the \loglin models discussed in \secref{sec:loglin-goodfit}, this is also referred to
as the \LR $G^2$ statistic.}

\begin{equation}\label{eq:pois-deviance}
D (\vec{y}, \vec{\widehat{\mu}}) =
  2 \sum_{i=1}^n \left[ y_i \log_e \left( \frac{y_i}{\widehat{\mu}_i}
    \right) - (y_i - \widehat{\mu}_i) \right] \period
\end{equation}
For a GLM with $p$ parameters, both the Pearson and residual deviance statistics follow
approximate $\chi^2_{n-p}$ distributions with $n-p$ degrees of freedom.

\ixoff{generalized linear model!goodness-of-fit}

% \section{GLMs for binomial data}\label{sec:glm-binomial}
%
% \TODO{Don't need to include this, because these models were extensively treated in \chref{ch:logistic}.}

\subsection{Comparing non-nested models}\label{sec:glm-nonnest}
\ixon{generalized linear model!non-nested models}
\ixon{non-nested models}

The flexibility of the GLM and its extensions allows us to fit models
to the same data using different families and different link functions, and to
fit models that allow for overdispersion (\secref{sec:glm-overdisp})
or that make special provisions for zero counts (\secref{sec:glm-zeros}).
One price paid for this additional versatility is that standard
LR tests and $F$ tests (such as provided by \func{anova}
and \func{linearHypothesis} in the \Rpackage{car})
do not apply to models that are not nested; that is, where one
model cannot be represented as a restricted, special case of another.

\ix{AIC}
\ix{BIC}
For models estimated by maximum likelihood, one general route to comparing
non-nested models is through the AIC information criterion proposed initially
by \citet{Akaike:73} and the related BIC criterion \citep{Schwartz:78},
based on the fitted log-likelihood function:
\begin{eqnarray}
\textrm{AIC} & = & -2 \log_e \mathcal{L} + 2 k \period\\
\textrm{BIC} & = & -2 \log_e \mathcal{L} + \log_e(n) k \period
\end{eqnarray}
As noted in \secref{sec:loglin-goodfit}, these both penalize models with larger $k$,
the number of parameters in the model, with BIC adding a greater penalty with
larger sample size.
However, because they are based only on the
maximized log-likelihood, they are agnostic as to whether models are nested or not,
and give comparable results (lower is better) provided the same observations have
been used in all models.

In \R, these results are given for a collection of models by the generic functions
\func{AIC} and \func{BIC}; these can be calculated for any model for which
\func{logLik} and (for BIC) \func{nobs} methods exist.
The \pkg{vcdExtra} function \func{LRstats} is a convenient wrapper for these
methods.

AIC and BIC do not give significance tests for assessing whether one model is
significantly ``better'' than another.  A series of tests that \emph{do} this was proposed by
\citet{Vuong:1989}: they 
%, unsurprisingly called .
\ix{model building}
\ix{nested models}
are based on comparing the predicted probabilities
or the pointwise log-likelihoods of the two models, and test the null hypothesis
that each is equally close to the saturated model, against the alternative that
one model is closer. The different tests handle nested, partially
nested and non-nested cases. However, whenever \term{Vuong's
  test} is mentioned in literature, this typically refers to the test
assuming that both models are \emph{strictly} non-nested, which may not be obvious to see in all cases.%
\footnote{The test versions for (partially) nested models are
  difficult to compute in practice, and at the time of writing, no
  implementation for them is available for \R.}
For example, some models may neither be nested
or non-nested, but \emph{overlapping}, that is, yield the same moments
and fit statistics only for some, not all data. However, our use
of Vuong's test will be confined to count data models, precluding 
most of these issues.

For two such models, let $f_1 (y_i \given \vec{x}_i, \vec{\theta}_1)$
be the density function under model 1, with parameters $\vec{\theta}_1$
and similarly
$f_2 (y_i \given \vec{x}_i, \vec{\theta}_2)$ under model 2 with parameters $\vec{\theta}_2$,
where $f_1(\bullet)$ and $f_2(\bullet)$ need not be the same.
Vuong's test compares these based on the observation-wise log-likelihood ratios,
%\newcommand{\ell}{\mathcal{l}}
\begin{equation*}
\ell_i = \log_e \left(
              \frac{f_1 (y_i \given \vec{x}_i, \vec{\widehat{\theta}}_1)}
                   {f_2 (y_i \given \vec{x}_i,
                     \vec{\widehat{\theta}}_2)} \right) \period
\end{equation*}
The test statistic is
\begin{equation*}
 V = \frac{\bar{\ell} - \textrm{penalty}} {\sqrt{n} s_\ell} \comma
\end{equation*}
where $\bar{\ell}$ is the mean of the $\ell_i$, $s_\ell$ is their variance, and
penalty is an adjustment for model parsimony, typically taken as
$\log(n) (k_1 - k_2)/2$ when model 1 has $k_1$ parameters in $\vec{\theta}_1$
and model 2 has $k_2$ parameters in $\vec{\theta}_2$.

The test statistic $V$ has an asymptotic normal $N(0,1)$ distribution,
and is directional, with large positive values favoring model 1, and large
negative values favoring model 2.
This test is implemented as the \func{vuong} function in the
\Rpackage{pscl}, and a more flexible version is provided by
\func{vuongtest} in \Rpackage{nonnest2}%
\footnote{This also allows for testing \emph{nested} models where the full
  model is not assumed to be correct as required by classical likelihood
  ratio tests, and also for other models than count regression models,
such as Structural Equation Models (SEMs).}.
\ixoff{generalized linear model!non-nested models}
\ixoff{non-nested models}

\section{GLMs for count data}\label{sec:glm-count}
\ixon{generalized linear model!count data}
<<count-data, child='ch11/count.Rnw'>>=
@
\ixoff{generalized linear model!count data}

<<crabs1, child='ch11/crabs1.Rnw'>>=
@

\section{Models for overdispersed count data}\label{sec:glm-overdisp}
\ixon{generalized linear model!overdispersion}
\ixon{overdispersion}

In practice, the Poisson model is often very useful for describing the
relationship between the mean $\mu_i$ and the linear predictors,
but typically underestimates the variance in the data.
The consequence is that the Poisson standard errors are too small,
rendering the Wald tests of coefficients, $z_j = \widehat{\beta}_j / \mathrm{se} (\widehat{\beta}_j) $
\ix{Wald test}
(and other hypothesis test statistics)
too large, and thus overly liberal.

\ix{likelihood ratio test}
\ix{deviance}
In applications of the GLM, overdispersion is usually assessed by the \LR
test of the deviance (or the Pearson statistic) given in \secref{sec:glm-goodfit},
but there is a subtle problem here. Lack of fit in a GLM for count data can result
either from a mis-specified model for the systematic component
(omitted or unmeasured predictors, nonlinear relations, etc.)
or from failure of the Poisson mean = variance assumption.
Thus, use of these methods requires some high degree of confidence that the
systematic part of the model has been correctly specified, so that any
lack of fit can be attributed to overdispersion.

One way of dealing with this is to base inference on
so-called \emph{sandwich} covariance estimators that are robust against
some types of model mis-specification.  In \R, this is provided by the
\func{sandwich} function in the \Rpackage{sandwich}, and can be used
with \code{coeftest(model, vcov = sandwich)} to give
overdispersion-corrected hypothesis tests%
\footnote{More precisely, given that the mean function of the model is correctly specified, the sandwich standard errors guard against misspecifications of the remaining likelihood, including overdispersion and heteroskedasticity.}
\citep{Zeileis:2004,Zeileis:2006}.
Alternatively, the Poisson model variance assumption can be relaxed
in the quasi-Poisson model and the negative-binomial model as
discussed below.


\subsection{The quasi-Poisson model}\label{sec:glm-quasi}
\ixon{generalized linear model!quasi-Poisson}
\ixon{quasi-Poisson}

One obvious solution to the problem of overdispersion for count data is the relaxed assumption
that the conditional variance is merely \emph{proportional} to the mean,
\begin{equation*}
\V (y_i | \eta_i) = \phi \mu_i \period
\end{equation*}
Overdispersion is the common case of $\phi > 1$, implying that the conditional variance
increases faster than the mean, but the opposite case of
underdispersion, $\phi < 1$, is also possible, though relatively rare in practice.
This strategy entails estimating the dispersion parameter $\phi$ from the data,
and gives the \term{quasi-Poisson model} for count data.

\ix{method-of-moments}
\ix{residuals!deviance}
One possible estimate is the residual deviance divided by degrees of freedom.
However, it is more common to use the Pearson statistic, giving
a method-of-moments estimate with improved statistical properties:
\begin{equation*}
\widehat{\phi} =
\frac{X^2_P}{n-p} =
\sum_{i=1}^n \frac{(y_i - \widehat{\mu}_i)^2}{\widehat{\mu}_i} \left/
  (n-p) \right. \period
\end{equation*}

It turns out that this model gives the same coefficient estimates as the standard
Poisson GLM, but inference is adjusted for over/under dispersion.
In particular, following \eqref{eq:varbeta},
the standard errors of the model coefficients are multiplied by
$\widehat{\phi}^{1/2}$ and so are inflated when overdispersion is present.
In \R, the quasi-Poisson model with this estimated dispersion parameter is
fitted with the \func{glm} function, by setting \code{family=quasipoisson}.

\begin{Example}[phdpubs2]{Publications of PhD candidates}

For the \data{PhdPubs} data, the deviance and Pearson estimates of dispersion $\phi$
can be calculated using the results of the Poisson model saved in the
\code{phd.pois} object.  The Pearson estimate, 1.83, indicates that
standard errors of coefficients in this model should be multiplied by
$\sqrt{1.83} = 1.35$, a 35\% increase, to correct for overdispersion.

<<phdpubs2-phi>>=
with(phd.pois, deviance / df.residual)
sum(residuals(phd.pois, type = "pearson")^2) / phd.pois$df.residual
@
The quasi-Poisson model is then fitted using \func{glm} as:
<<phdpubs2-quasi>>=
phd.qpois <- glm(articles ~ ., data = PhdPubs, family = quasipoisson)
@
\begin{sloppypar}
For use in other computation, the  dispersion parameter estimate $\widehat{\phi}$ can be obtained as the
\code{dispersion} value of the \func{summary} method for a quasi-Poisson model.
\end{sloppypar}
<<phdpubs2-phi2>>=
(phi <- summary(phd.qpois)$dispersion)
@
Note that this value can be compared to the variance/mean ratio of 2.91 calculated for the
marginal distribution in \exref{ex:phdpubs1}; there is considerable improvement taking the
predictors into account.

\end{Example}
\ixoff{quasi-Poisson}
\ixoff{generalized linear model!quasi-Poisson}
\ixoff{generalized linear model!overdispersion}
\ixoff{overdispersion}

\subsection{The negative-binomial model}\label{sec:glm-negbin}
\ixon{generalized linear model!negative binomial}
\ixon{negative binomial distribution!model}
\ix{count data}

The negative-binomial (NB) model for count data was introduced in \secref{sec:negbin}
as a different generalization of the Poisson model that allows for overdispersion.
In the context of the GLM, this can be developed as the extended form where
the distribution of $y_i \given \vec{x}_i$ where the mean $\mu_i$ for fixed
$\vec{x}_i$ can vary across observations $i$ according to a gamma distribution
with mean $\mu_i$ and a constant shape parameter, $\theta$, reflecting the
additional variation due to heterogeneity.

For a fixed value of $\theta$, the negative-binomial is another special case of
the GLM.
The expected value of the response is again
$\E(y_i) = \mu_i$, but the variance function is $\V(y_i) = \mu_i + \mu_i^2 / \theta$,
so the variance of $y$ increases more rapidly than that of the Poisson distribution.
Some authors (e.g., \citet{Agresti:2013,Hilbe:2014}) prefer to parameterize the variance
function in terms of $\alpha = 1/\theta$, giving
\begin{equation*}
\V(y_i) = \mu_i + \mu_i^2 / \theta = \mu_i + \alpha \mu_i^2 \comma
\end{equation*}
so that $\alpha$ is a kind of dispersion parameter.  Note that as $\alpha \rightarrow 0$,
$\V(y_i) \rightarrow \mu_i$ and the negative-binomial converges to the Poisson.

The \Rpackage{MASS} provides the family function \code{negative.binomial(theta)} that
can be used directly with \func{glm} provided that the argument \code{theta} is specified.
\ix{geometric distribution}
\ix{distributions!geometric}
One example would be the related geometric distribution
(\secref{sec:geometric}) that is the special case of $\theta=1$. 
This can be fitted in \R by setting
\code{family=negative.binomial(theta=1)} in the call to \func{glm}.

Most often, $\theta$ is unknown and must be estimated from the data.
In this case, the negative-binomial model is not a special case of the GLM,
but it is possible to obtain maximum likelihood estimates of both
$\vec{\beta}$ and $\theta$, by iteratively estimating $\vec{\beta}$ for fixed $\theta$
and vice-versa. This method is implemented in the \func{glm.nb} in the package \pkg{MASS}.

\begin{Example}[crabs-nbin]{Mating of horseshoe crabs}
For example, for the \data{CrabSatellites} data,
we can fit the general negative-binomial model with
$\theta$ free.
<<crabs-nbin>>=
library(MASS)
crabs.nbin <- glm.nb(satellites ~ weight + color, 
                     data = CrabSatellites1)
crabs.nbin$theta
@
The estimated value $\widehat{\theta}$ returned by \func{glm.nb} is not very far from 1.
Hence, we might also consider fixing $\theta=1$, as illustrated below.
<<crabs-nbin1>>=
crabs.nbin1 <- glm(satellites ~ weight + color, data = CrabSatellites1,
                   family = negative.binomial(1))
@
\end{Example}

% until I finish the negbin section....
<<phdpubs-nbin, echo=FALSE>>=
library(MASS)
phd.nbin  <- glm.nb(articles ~ ., data = PhdPubs)
@

\ixoff{generalized linear model!negative binomial}
\ixoff{negative binomial distribution!model}

\subsection{Visualizing the mean--variance relation}

The quasi-Poisson and negative-binomial models have different variance functions, and one way to
visualize which provides a better fit to the data is to group the data according to the
fitted value of the linear predictor, calculate the mean and variance for each group, and
then plot the variances against the means.
A smoothed curve will then approximate the \emph{empirical} mean--variance relationship.
To this, we can add curves showing the mean--variance function implied by various models.%
\footnote{
This idea and the example that follows was suggested by Germ\'an Rodrigues
in a Stata example given at
\url{http://data.princeton.edu/wws509/stata/overdispersion.html}.
}

\begin{Example}[phdpubs3]{Publications of PhD candidates}
For the \data{PhdPubs} data, the fitted values are obtained with \func{fitted} for the
Poisson and negative binomial models. Either set can be used to categorize the observations
into groups for the purpose of calculating means and variances of the response.


<<phdpubs3-fitted>>=
fit.pois <- fitted(phd.pois, type = "response")
fit.nbin <- fitted(phd.nbin, type = "response")
@
Here we use a simpler version of the \func{cutfac} function to group a numeric variable
into quantile-based groups.  \func{cutq} also uses deciles by default, and just uses
\ix{factor}
simple integer values for the factor labels.
<<cutq>>=
cutq <- function(x, q = 10) {
    quantile <- cut(x, breaks = quantile(x, probs = (0 : q) / q),
        include.lowest = TRUE, labels = 1 : q)
    quantile
}

@
Using this, we create a variable \code{group} giving 20 quantile groups of the fitted values,
and then use \func{aggregate} to find the mean and variance of the number of articles
in each group.
<<qdat1>>=
group <- cutq(fit.nbin, q = 20)
qdat <- aggregate(PhdPubs$articles,
          list(group),
          FUN = function(x) c(mean = mean(x), var = var(x)))
qdat <- data.frame(qdat$x)
qdat <- qdat[order(qdat$mean),]
@
We can then calculate the theoretical variances implied by the quasi-Poisson and negative-binomial models:
<<qdat2>>=
phi <- summary(phd.qpois)$dispersion
qdat$qvar <- phi * qdat$mean
qdat$nbvar <- qdat$mean + (qdat$mean^2) / phd.nbin$theta
head(qdat)
@

\ix{generalized linear model!plotting}
The plot, shown in \figref{fig:phd-mean-var-plot}, then simply plots the points and
uses \func{lines} to plot the model-implied variances.
<<phd-mean-var-plot, h=6, w=9, out.width='.75\\textwidth', cap='Mean--variance functions for the PhdPubs data. Points show the observed means and variances for 20 quantile groups based on the fitted values in the negative-binomial model. The labeled lines and curves show the variance functions implied by various models.'>>=
with(qdat, {
  plot(var ~ mean, xlab = "Mean number of articles", ylab = "Variance",
       pch = 16, cex = 1.2, cex.lab = 1.2)
  abline(h = mean(PhdPubs$articles), col = gray(.40), lty = "dotted")
  lines(mean, qvar, col = "red", lwd = 2)
  lines(mean, nbvar, col = "blue", lwd = 2)
  lines(lowess(mean, var), lwd = 2, lty = "dashed")
  text(3, mean(PhdPubs$articles), "Poisson", col = gray(.40))
  text(3, 5, "quasi-Poisson", col = "red")
  text(3, 6.7, "negbin", col = "blue")
  text(3, 8.5, "lowess")
})
@
We can see from this plot that the variances implied by the quasi-Poisson and negative-binomial
models are in reasonable accord with the data and with each other up to a mean of about 2.5.
They diverge substantially at the upper end, for the 20--30\% of the most productive
candidates, where the quadratic variance function of the negative-binomial provides a
better fit.

Finally, we can also compare the standard errors of coefficients
for the various methods designed to correct for overdispersion.  These are extracted
as the diagonal elements of the \func{vcov} and \func{sandwich} methods from the model objects.
<<phdpubs3-SE>>=
library(sandwich)
phd.SE <- sqrt(cbind(
  pois = diag(vcov(phd.pois)),
  sand = diag(sandwich(phd.pois)),
  qpois = diag(vcov(phd.qpois)),
  nbin = diag(vcov(phd.nbin))))
round(phd.SE, 4)
@
For this example, the sandwich, quasi-Poisson, and negative-binomial methods give similar results,
all about 40\% larger on average than those from the Poisson model.
\end{Example}

\subsection{Testing overdispersion}\label{sec:glm-disptest}
\ixon{overdispersion}

The forms of overdispersion seen in these examples and in \figref{fig:phd-mean-var-plot}
give rise to a statistical test
(\citealt{CameronTrivedi:1990}; \citealt[\S 3.4]{CameronTrivedi:1998})
for the
null hypothesis of Poisson variation, $H_0 : \V(y) = \mu$, against an alternative that the variance
has a particular form depending on the mean,
\begin{equation*}
\V(y) = \mu + \alpha \times f(\mu) \comma
\end{equation*}
where $f(\mu)$ is a given transformation function of the mean.

Overdispersion corresponds to $\alpha > 0$ and underdispersion to $\alpha < 0$.
The coefficient $\alpha$ can be estimated by an auxiliary OLS regression (without an intercept), i.e., of the
form
\begin{verbatim}
lm(var ~ -1 + f(mean))
\end{verbatim}
and tested with the corresponding $t$ (or $z$) statistic, which is asymptotically standard normal under the null hypothesis.

Common specifications of the transformation function are  $f(\mu) = \mu$ and $f(\mu) = \mu^2$. The first corresponds to
an NB model with a linear variance function (called NB1 by various authors)
or a quasi-Poisson model with dispersion parameter $\phi$, i.e.,
\begin{equation*}
\V(y) = (1 + \alpha) \mu = \phi \mu \period
\end{equation*}
The second is the more traditional form with quadratic variance function described in \secref{sec:glm-negbin}
(called NB2 by some authors).

These tests are carried out using the \func{dispersiontest} function
in the \Rpackage{AER}, the companion software of \citet{kleiber+zeileis:2008}.
The first argument is a Poisson GLM model; the second specifies the alternative hypothesis,
either as an integer power of $\mu$ or a function of the mean.
<<phd-disptest>>=
library(AER)
dispersiontest(phd.pois)
dispersiontest(phd.pois, 2)
@
These tests use a specified alternative hypothesis, so there is no way to compare directly which of
the NB1 or NB2 models is better or worse, except by using methods such as
AIC or BIC described in \secref{sec:glm-nonnest}.
\ixoff{overdispersion}


\subsection{Visualizing goodness-of-fit}\label{sec:glm-visfit}
\ixon{generalized linear model!goodness-of-fit}
\ixon{goodness-of-fit}

Even with correction for overdispersion, goodness-of-fit tests provide only an overall
summary of model fit.  Some specialized tests for particular forms of overdispersion
are also available (e.g., see \citet[\C 5]{CameronTrivedi:1998}),
but these only identify general problems and cannot provide detailed indications of
the possible source of these problems.

\ix{rootogram}
In \chref{ch:discrete}, we illustrated the use of rootograms for visualizing goodness-of-fit
to a wide variety of discrete distributions using the \func{plot} method for
class \class{goodfit} objects with the \Rpackage{vcd}.  However, those methods were
developed for one-way discrete distributions without explanatory variables.

\citet{KleiberZeileis:2014} have generalized this idea to the wider class of
GLM-related count regression models considered here.
The \Rpackage{countreg} provides a new implementation of \func{rootogram}
with methods for all of these models (and others not mentioned).
We illustrate these plots for the models considered to this point, and then extend
this use for models allowing for excess zero counts in \secref{sec:glm-zeros}.

\begin{Example}[phdpubs4]{Publications of PhD candidates}
For the \data{PhdPubs} data, \figref{fig:phdpubs4-rootogram} shows hanging rootograms for the
Poisson and negative-binomial models produced using \code{countreg::rootogram}%
\footnote{
At the time of this writing, \code{rootogram} in \pkg{countreg} conflicts with
the version in \pkg{vcd}, so we qualify the use here with the package name.
}
on the fitted model objects.  We are looking both for general patterns of under/over fit, as well
as counts that stand out as poorly fitted against the background.

<<phdpubs4-rootogram, w=6, h=4, out.width='.49\\textwidth', cap='Hanging rootograms for the PhdPubs data.'>>=
library(countreg)
countreg::rootogram(phd.pois, max = 12, 
                    main = "PhDPubs: Poisson")
countreg::rootogram(phd.nbin, max = 12, 
                    main = "PhDPubs: Negative-Binomial")
@
The Poisson model shows a systematic, wave-like pattern with excess zeros, too few observed frequencies for
counts of
1--3, but generally greater frequencies for counts of 4 or more.  The negative-binomial model
clearly fits much better, though there is a peculiar tendency among the smaller
frequencies for 8 or more articles.
\end{Example}

\begin{Example}[crabs2]{Mating of horseshoe crabs}
\figref{fig:crabs2-rootogram} shows similar plots for the same two models fit to the number of
crab satellites.  The fit of the Poisson model clearly reveals the excess of zero male satellites.
For the negative-binomial, the rootogram no longer exhibits same wave-like pattern,
however, the underfitting of the count for 0 and overfitting for counts 1--2 is
characteristic of data with excess zeros.

<<crabs2-rootogram, w=6, h=4, out.width='.49\\textwidth', cap='Hanging rootograms for the CrabSatellites data.'>>=
countreg::rootogram(crabs.pois, max = 15, 
                    main = "CrabSatellites: Poisson")
countreg::rootogram(crabs.nbin, max = 15, 
                    main = "CrabSatellites: Negative-Binomial")
@
\end{Example}
\ixoff{generalized linear model!goodness-of-fit}
\ixoff{goodness-of-fit}


\section{Models for excess zero counts}\label{sec:glm-zeros}

\ixon{generalized linear model!excess zeros}
\ixon{excess zeros}
\ixon{zeros!excess}
<<zeros, child='ch11/zeros.Rnw'>>=
@
\ixoff{generalized linear model!excess zeros}
\ixoff{excess zeros}
\ixoff{zeros!excess}

%\subsection{Zero-inflated models}\label{sec:glm-zip}
%\subsection{Hurdle models}\label{sec:glm-hurdle}

\section{Case studies}\label{sec:glm-casestudies}

In this section, we introduce two extended examples, designed to illustrate aspects of
exploratory analysis, visualization, model fitting, and interpretation for count data GLMs.
The first (\secref{sec:glm-case-cod})
concerns another well-known data set from ethology, where
\begin{seriate}
\item excess zeros require special treatment,
\item the occurrence of zero counts has substantive meaning, and
\item an interaction between two factors is important.
\end{seriate}

The second case study (\secref{sec:glm-case-nmes})
uses a larger, also well-known
data set from health economics, with more predictors and more
potential interactions. The emphasis shifts here from fitting and comparing models with
different distributional forms and link functions to selecting terms for an adequate descriptive
and explanatory model. Another feature of these examples is that the relatively large sample size
in this data supports a wider range of model complexity than is available in smaller samples.


\subsection{Cod parasites}\label{sec:glm-case-cod}
The cod fishery is extremely important to the economy of Norway, so anything that affects the
health of the cod population and its ecosystem can have severe consequences.
The red king crab \emph{Paralithodes camtschaticus} was deliberately introduced by Russian scientists
to the Barents Sea in the 1960s and 1970s from its native area in the North Pacific. The carapace of these crabs is used by the leech \emph{Johanssonia arctica} to deposit its eggs. This leech in turn is a vector for the blood parasite
\emph{Trypanosoma murmanensis} that can infect marine fish, including cod.


\citet{Hemmingsen-etal:2005} examined cod for trypanosome infections during annual cruises along the coast of Finnmark in North Norway over three successive years and in four different areas
(A1: S{\o}r{\o}ya; A2: Mager{\o}ya; A3: Tanafjord; A4: Varangerfjord).
They show that trypanosome infections are strongest in the area Varangerfjord where the density of red king crabs is highest. Thus, there is evidence that the introduction of the foreign red king crabs had an indirect detrimental effect on the health of the native cod population. This situation stands out because it is not an introduced \emph{parasite} that is dangerous for a native host, but rather an introduced \emph{host} that promotes transmission of two endemic parasites. They call the connections among these factors ``an unholy trinity.''%
\footnote{\label{fn:russian}
The four areas A1--A4 are arranged from east to west, with Varangerfjord (A4) closest to the Russian
Kola Peninsula where the red king crabs initially migrated.  A more specific test of the
``Russian hypothesis'' could be developed by treating area as an ordered factor and testing
the linear component.  We leave this analysis to an exercise for the reader.
}

<<cod1, child='ch11/cod1.Rnw'>>=
@

\subsection{Demand for medical care by the elderly}\label{sec:glm-case-nmes}

A large cross-sectional study was carried out by the U.S. National Medical Expenditure
Survey (NMES) in 1987--1988 to assess the demand for medical care, as
measured by the number of physician/non-physician office visits and the
number of hospital outpatient visits to a physician/non-physician.
The survey was based upon a representative national probability sample 
of the civilian non-institutionalized population and individuals 
admitted to long-term care facilities during 1987.  A subsample of $4,406$
individuals aged 66 and over, all of whom are covered by Medicare, is contained
in the \data{NMES1988} data set in the \Rpackage{AER}.
These data were previously analyzed by \citet{DebTrivedi:1997}
and \citet{Zeileis-etal:2008}, from which this account borrows.
The objective of the study and these analyses is to create a descriptive, and hopefully predictive, model
for the demand for medical care in this elderly population.

<<nmes1, child='ch11/nmes1.Rnw'>>=
@

\section{Diagnostic plots for model checking}\label{sec:glm-diag}
\ixon{generalized linear model!diagnostic plots}
\ixon{diagnostic plots}

\epigraph{Models, of course, are never true, but fortunately it is only necessary that they be useful.}{G. E. P. Box,
\emph{Some Problems of Statistics of Everyday Life}, \citeyear{Box:1979}, p. 2}

Most of the model diagnostic methods for classical linear models extend in a relatively direct way
to GLMs.
These include
\begin{seriate}
  \item plots of residuals of various types,
  \item diagnostic measures and plots of leverage and influence,
as well as some
  \item more specialized plots (component-plus-residual plots, added-variable plots)
designed to show the specific contribution of a given predictor among others in a linear model.
\end{seriate}
These methods were described in \secref{sec:logist-infl} in the context of logistic regression,
and most of that discussion is applicable here in wider GLM class.

One additional complication here is that in any GLM we are specifying:
\begin{seriate}
  \item the distribution of the random component, which for count data models may also involve a dispersion
  parameter or other additional parameters;
  \item the form of the linear predictor, $\eta = \vec{x}\trans \beta = \beta_0 + \beta_1 x_1 + \cdots$,
  where all important regressors have been included, and on the right scale;
  \item the correct link function, $g(\mu) = \eta$
  transforming the conditional mean of the response $y$ to the predictor variables where they have linear
  relationships.
\end{seriate}

Thus, there are a lot of things that could go wrong, but the famous quote from George Box should remind us
that all models are approximate, and the goal for model diagnosis should be an adequate model, useful
for description, estimation, or prediction as the case may be. What is most important is that our models
should not be misleadingly wrong, that is, they should not affect substantive conclusions or interpretation.

\subsection{Diagnostic measures and residuals for GLMs}

Estimation of GLMs by maximum likelihood uses an iterative weighted least squares (IWLS) algorithm,
and many of the diagnostic measures for these models are close counterparts of their forms for
classical linear models.  Roughly speaking, these follow from replacing
$\vec{y}$ and $\widehat{\vec{y}}$ in least squares diagnostics by a ``working response'' and
$\widehat{\vec{\eta}}$, replacing the residual variance $\widehat{\sigma}^2$ by $\widehat{\phi}$,
and using a weighted form of the Hat matrix.

\subsubsection{Leverage}
\ix{generalized linear model!leverage}
Hat values, $h_i$, measuring \term{leverage} or the potential of an observation to affect the fitted model,
are defined as the diagonal elements of the hat matrix $\mat{H}$, using the weight matrix
$\mat{W}$ from the final IWLS iteration.  This has the same form as in a weighted least squares
regression using a fixed $\mat{W}$ matrix:
\begin{equation*}
\mat{H} = \mat{W}^{1/2} \mat{X} (\mat{X}\trans \mat{W}  \mat{X} )^{-1} \mat{X}\trans \mat{W}^{1/2} \period
\end{equation*}
In contrast to OLS, the weights depend on the $\vec{y}$ values as well as the $\mat{X}$ values, so
high leverage observations do not necessarily reflect only unusualness in the space of the
predictors.

\subsubsection{Residuals}
\ix{residuals}
Several types of residuals can be defined starting from the goodness-of-fit measures
discussed in \secref{sec:glm-goodfit}.
\ix{residuals!response}
The \term{raw residual} or \term{response residual} is simply the difference $y_i - \widehat{\mu}_i$
between the observed response $y_i$ and the estimated mean,
$\widehat{\mu} = g^{-1} (\widehat{\eta}_i) = g^{-1} (\vec{x}_i\trans \widehat{\beta})$.

From this, the \term{Pearson residual} is defined as
\ix{residuals!Pearson}
\begin{equation}\label{eq:res-pearson}
r^P_i = \frac{y_i - \widehat{\mu}_i} {\sqrt{\widehat{\V}(y_i)}}
\end{equation}
and the \term{deviance residual} is defined as the signed square root of the contribution of observation $i$ to the
deviance in \eqref{eq:pois-deviance}.
\ix{residuals!deviance}
\begin{equation}\label{eq:res-deviance}
r^D_i = \sign (y_i - \widehat{\mu}_i) \sqrt {d_i} \period
\end{equation}

The Pearson and deviance residuals do not account for dispersion or for differential leverage
(which makes their variance smaller), so \term{standardized residuals} (sometimes called \emph{scaled} residuals)
can be calculated as
\begin{eqnarray}
\widetilde{r}^P_i & = & \frac{r^P_i} {\sqrt{\widehat{\phi} (1-h_i)}}
                        \period \label{eq:res-pearson-s} \\
\widetilde{r}^D_i & = & \frac{r^D_i} {\sqrt{\widehat{\phi} (1-h_i)}} \period \label{eq:res-deviance-s}
\end{eqnarray}
These have approximate standard normal $\mathcal{N} (0, 1)$ distributions, and will generally
have quite similar values (except for small values in $\widehat{\mu}$).
Consequently, convenient thresholds like $ | \widetilde{r}_i | > 2$ or $ | \widetilde{r}_i | > 4$
are useful for identifying unusually large residuals.

Finally, the \term{studentized residual} (or \emph{deletion} residual)
\ix{residuals!studentized}
\ix{residuals!standardized}
gives the standardized residual
that would result from omitting each observation in turn and calculating the change in the deviance.
Calculating these exactly would require refitting the model $n$ times,
but an approximation is
\begin{equation}
\widetilde{r}^S_i = \sign (y_i - \widehat{\mu}_i) \sqrt{ (\widetilde{r}^D_i)^2 + (\widetilde{r}^P_i)^2 h_i /(1-h_i) } \period
\end{equation}
From the theory of classical linear models, these provide formal outlier tests for individual observations
\citep[\S 11.3]{Fox:2008} as a \emph{mean-shift} outlier model that dedicates an additional parameter
\ix{multiple testing}
\ix{multiplicity}
\ix{Bonferroni correction}
to fit observation $i$ exactly.  To correct for multiple testing and a focus on the largest absolute
residuals, it is common to apply a Bonferroni adjustment to the $p$-values of these tests, multiplying them by $n$.

For a class \class{glm} object, the function \code{residuals(object, type)} returns the unstandardized
residuals for \code{type="pearson"} or \code{type="deviance"}.%
\footnote{Other types include
raw response residuals (\code{type="response"}),
working residuals (\code{type="working"}), and
partial residuals (\code{type="partial"}).
}
The standardized versions are obtained using \func{rstandard}, again with a \code{type} argument
for the Pearson or deviance flavor.  \func{rstudent} calculates the studentized deletion residuals.

\subsubsection{Influence}
\ixon{influence}
As discussed in \secref{sec:logist-infl} in the context of logistic regression,
influence measures attempt to evaluate the effect
that an observation exerts on the parameters, fitted values, or goodness-of-fit statistics
by comparing a statistic calculated for all the data with the value obtained omitting
each observation in turn.  Again, approximations are used to estimate these effects
without laboriously refitting the model $n$ times.

Overall measures of influence include
\ix{Cook's distance}
\begin{itemize*}
  \item Cook's distance (\eqref{eq:cookd2}),
a squared measure of the difference $\widehat{\vec{\beta}} - \widehat{\vec{\beta}}_{(-i)}$
in all $p$ coefficients in the model.  The approximation used in \func{cooks.distance} is
\begin{equation*}
C_i = \frac{\widetilde{r}_i h_i}{\widehat{\phi} \: p \: (1-h_i)}  \period
\end{equation*}
This follows \citet{Williams:87}, but scales the result by the estimated dispersion $\widehat{\phi}$
as an approximate $F_{p, n-p}$ statistic rather than $\chi^2_p$.
\ix{DFFITS}
  \item DFFITS, the standardized signed measure of the difference of the fitted value
  $\widehat{\mu}_i$ using all the data and the value  $\widehat{\mu}_{(-i)}$ omitting observation $i$.
\end{itemize*}

\begin{Example}[phdpubs5]{Publications of PhD candidates}
For models that inherit methods from the \class{glm} class (including NB models fit using \func{glm.nb}),
the simplest initial diagnostic plots are provided by the \func{plot} method.
\figref{fig:phdpubs5-plot} shows the default \emph{regression quartet} of plots for the
negative-binomial model \code{phd.nbin} examined in earlier examples.  By default, the
\code{id.n=3} most noteworthy observations are labeled with their row names from the original
data set.

<<phdpubs5-plot, h=8, w=8, echo=2, out.width='.7\\textwidth', cap='Default diagnostic plots for the negative-binomial model fit to the PhdPubs data.'>>=
op <- par(mfrow=c(2,2), mar=c(4,4,2,1)+.1, cex.lab=1.2)
plot(phd.nbin)
par(op)
@
The plot of residuals against predicted values in the upper left panel of \figref{fig:phdpubs5-plot} should
show no overall systematic trend for a well-fitting model.  The smoothed loess 
\ix{loess}
curve in red suggests that
this is not the case.

Several functions in the \Rpackage{car} make these plots more flexibly and with greater control of the details.
\figref{fig:phdpubs5-resplot1} shows the plot of residuals against predicted values two ways.
The right panel explains the peculiar pattern of diagonal band of points.  These correspond to the
different discrete values of the response variable, number of articles published.
<<phdpubs5-resplot1, h=6, w=6, out.width='.5\\textwidth', cap='Plots of residuals against the linear predictor using residualPlot(). The right panel shows that the diagonal bands correspond to different values of the discrete response.'>>=
library(car)
residualPlot(phd.nbin, type = "rstandard", col.smooth = "red", id.n = 3)
residualPlot(phd.nbin, type = "rstandard",
             groups = PhdPubs$articles, key = FALSE, linear = FALSE, 
	     smoother = NULL)
@
Other useful plots show the residuals against each predictor.  For a good-fitting model, the average
residual should not vary systematically with the predictor.
As shown in \figref{fig:phdpubs5-resplot2}, \func{residualPlot} draws a lowess smooth, and
also computes a curvature test for each of the plots by adding a quadratic term and testing the quadratic to be zero.
%\DONE{Trap this meaningless error using \func{try} in \pkg{car}.}
<<phdpubs5-resplot2, h=6, w=6, out.width='.5\\textwidth', cap='Plots of residuals against two predictors in the phd.nbin model. Such plots should show no evidence of a systematic trend for a good-fitting model.'>>=
residualPlot(phd.nbin, "mentor", type = "rstudent",
             quadratic = TRUE, col.smooth = "red", col.quad = "blue", 
	     id.n = 3)
residualPlot(phd.nbin, "phdprestige", type = "rstudent",
             quadratic = TRUE, col.smooth = "red", col.quad = "blue", 
	     id.n = 3)
@
In the plot at the left for number of articles by the student's mentor, the curvature is quite pronounced: at high values of
\code{mentor}, nearly all of the residuals are negative, these students publishing fewer articles than
would be expected. This would indicate a problem in the scale for \code{mentor}
if there were more observations at the high end;  but only about 1.5\% points occur for \code{mentor>45},
so this can be discounted.

\figref{fig:phdpubs5-influenceplot} gives a better version of the influence plot shown in the lower right
panel of \figref{fig:phdpubs5-plot}.
\ix{Cook's distance}
\ix{residuals!studentized}
This plots studentized (deletion) residuals against leverage, showing
the value of Cook's distance by the area of the bubble symbol.
<<phdpubs5-influenceplot, h=6, w=8, out.width='.7\\textwidth', cap="Influence plot showing leverage, studentized residuals, and Cook's distances for the negative-binomial model fit to the PhdPubs data. Conventional cutoffs for studentized residuals are shown by dashed horizontal lines at $\\pm 2$; vertical lines show 2 and 3 times the average hat-value.">>=
influencePlot(phd.nbin)
@
Several observations are considered noteworthy, because of one or more of large absolute residual, large leverage, or
large Cook's distance. \func{influencePlot} uses different default rules for point labeling than does the
\func{plot} method, but provides many options to control the details.
Observation 328 stands out as having the largest leverage and a large negative residual;
case 913 has the largest absolute residual, but is less influential than case 915.%
\footnote{
The higher case numbers appear in these plots and diagnostics because the data set \data{PhdPubs} had been sorted
by the response, \var{articles}.
}

The \func{outlierTest} function in \pkg{car} gives a formal test of significance of the largest absolute
studentized residuals, with a Bonferroni-adjusted $p$-value accounting for choosing the largest values
among $n$ such tests. Individually, case 913 is extreme, but it is not at all extreme among
$n=915$ such tests, each using $\alpha=.05$.

<<phdpubs-outlierTest>>=
outlierTest(phd.nbin)
@
This example started with the negative-binomial model, the best-fitting from the previous examples.  It highlighted a
few features of the data not seen previously and worth considering, but doesn't seriously challenge the
substantive interpretation of the model.  This is what we hope for from model diagnostic plots.

\end{Example}
\ixoff{influence}

\subsection{Quantile--quantile and half-normal plots}
\ixon{quantile--quantile (QQ) plots}
\ixon{half-normal plot}
As we noted above, in theory
the standardized and studentized Pearson and deviance residuals have approximate
standard normal $\mathcal{N} (0,1)$
distributions (in large samples)
when the fitted model is correct.
This suggests a plot of the sorted residuals, $r_{(i)}$, against the
corresponding expected values, $z_{(i)}$,
an equal-sized sample of size $n$ would have in a
normal distribution.%
\footnote{
The subscripted notation $r_{(i)}$ (and $z_{(i)}$) denotes an
\emph{order statistic}, i.e., the
$i^{th}$ largest value in a set arranged in increasing order.
}

If the distribution of the residuals is approximately
normal, the points $(r_{(i)}, z_{(i)})$ should lie along a line with unit slope through the origin;
systematic or individual departure from this line signals a potential violation of assumptions.
The expected values are typically calculated as
$z_{(i)} = \Phi^{-1} \{ (i-\frac{3}{8}) / ( n + \frac{1}{4}) \}$,
where $\Phi^{-1} (\bullet)$ is the inverse normal, or normal quantile function, \func{qnorm} in \R.

Such plots, called \term{normal quantile plots}
or \term{normal QQ plots}, are commonly
used for GLMs with a quantitative response variable.
The upper right panel of \figref{fig:phdpubs5-plot} illustrates the form of such plots
produced by \func{plot} for a \class{glm} object.

One difficulty with the default plots is that it is hard to tell to what extent the points
deviate from the unit line because there is no visual reference for the line or
envelope to indicate expected variability about that line.
This problem is easily remedied using \func{qqPlot} from \pkg{car}.

\figref{fig:phdpubs6-qqplot} shows the result for the model \code{phd.nbin}.
The envelope lines used here are at the quartiles of the expected normal distribution.
They suggest a terrible fit, but, surprisingly, the largest three residuals are within the
envelope.
<<phdpubs6-qqplot, h=6, w=6, out.width='.5\\textwidth', cap='Normal QQ plot of the studentized residuals from the NB model for the PhdPubs data. The normal-theory reference line and confidence envelope are misleading here.'>>=
qqPlot(rstudent(phd.nbin), id.n = 3,
       xlab = "Normal quantiles", ylab = "Studentized residuals")
@

For GLMs with discrete responses, such plots are often disappointing, even with a
reasonably good-fitting model, because:
\begin{seriate}
  \item possible outliers can appear at both the lower and upper ends of the distribution of residuals;
  \item the theoretical normal distribution used to derive the envelope may not be well approximated in
  a given model.
\end{seriate}

\citet{Atkinson:81,Atkinson:87} suggested a more robust and useful version of these QQ plots:
half normal plots, with simulated confidence envelopes.
The essential ideas are:
\begin{itemize*}
 \item Model departures and outliers are often easier to see for
discrete data when the \emph{absolute values} of residuals are plotted,
because large positive and negative values are sorted together.
This gives the \textbf{\emph{half-normal plot}}, in which the
absolute values of residuals,  arranged in increasing order, $|r|_{(i)}$,
are plotted
against
$|z|_{(i)} = \Phi^{-1} \{ (n+i-\frac{1}{8}) / (2n + \frac{1}{2}) \}$.
All outliers will then appear  in the upper right of such a plot,
as points separated from the trend of the remaining cells.

  \item The normal-theory reference line, $|r|_{(i)} = |z|_{(i)}$
and the normal-theory confidence envelope can be replaced by simulating residuals
from the assumed distribution, that need not be normal.
The reference line is taken as the mean
of $S$ simulations and the envelope with $1-\alpha$ coverage is taken as
the $(\alpha/2, 1-\alpha/2)$ quantiles of their values.

  \item Specifically, for a GLM, $S$ sets of random observations $\vec{y}_j, j=1, 2, \dots S$
are generated from the fitted model, each with mean $\widehat{\vec{\mu}}$,
the fitted values under the model and with the \emph{same} distribution.
In \R, this is readily accomplished using the generic
\func{simulate} function;
the random variation around $\widehat{\mu}$ uses \func{rnorm}, \func{rpois},
\func{rnegbin}, etc., as appropriate for the family of the model.

  \item The same model is then fit
to each simulated $\vec{y}_j$, giving a new set of residuals for each simulation.
Sorting their absolute values then gives the simulation distribution used as
reference for the observed residuals.
\end{itemize*}

At the time of writing there is no fully general implementation of these plots in \R,
but the technique is not too difficult and is sufficiently useful to illustrate here.

\begin{Example}[phdpubs6]{Publications of PhD candidates}
First, calculate the sorted absolute values of the residuals $|r|_{(i)}$ and
their expected normal values, $|z|_{(i)}$.  The basic plot will be
\code{plot(expected, observed)}.
<<phdpubs6-obs, eval=FALSE>>=
observed <- sort(abs(rstudent(phd.nbin)))
n <- length(observed)
expected <- qnorm((1:n + n - 1/8) / (2*n + 1/2))
@
Then, use \func{simulate} to generate $S=100$ simulated response vectors around the fitted
values in the model. Here this uses the negative-binomial random number generator (\func{rnegbin})
with the same dispersion value ($\widehat{\theta} =$ \Sexpr{round(phd.nbin$theta, 3)})
estimated in the model.  The result, called \code{sims} here, is a data frame of
$n=915$ rows and $S=100$ columns, named \verb|sim_1, sim_2, ...|.
<<phdpubs6-sims, eval=FALSE>>=
S <- 100
sims <- simulate(phd.nbin, nsim = S)
simdat <- cbind(PhdPubs, sims)
@
The next step is computationally intensive, because we have to fit the NB model $S=100$ times,
and a little bit tricky, because we need to use the same model formula as the original,
but with the simulated $\vec{y}$.
We first define a function \code{resids} to do this for a given \code{y},
and then use a loop to calculate them all. To save computing time, the
coefficients from the \code{phd.nbin} model are used as starting values.
<<phdpubs6-simres, eval=FALSE>>=
# calculate residuals for one simulated data set
resids <- function(y)
  rstudent(glm.nb(y ~ female + married + kid5 + phdprestige + mentor,
                  data=simdat, start=coef(phd.nbin)))
# do them all ...
simres <- matrix(0, nrow(simdat), S)
for(i in 1:S) {
	simres[,i] <- sort(abs(resids(dat[,paste("sim", i, sep="_")])))
}
@
We can then use \func{apply} to compute the summary measures defining the center and limits for the
simulated confidence interval.
<<phdpubs6-env, eval=FALSE>>=
envelope <- 0.95
mean <- apply(simres, 1, mean)
lower <- apply(simres, 1, quantile, prob = (1 - envelope) / 2)
upper <- apply(simres, 1, quantile, prob = (1 + envelope) / 2)
@

\begin{figure}[htb]
  \centering
  \includegraphics[width=.5\textwidth]{ch11/fig/phd-halfnorm.pdf}
  \caption{Half-normal QQ plot of studentized residuals for the NB model fit to the PhdPubs data. The reference line and confidence envelope reflect the mean and (2.5\%, 97.5\%) quantiles of the simulation distribution under the negative-binomial model for the same data.}
  \label{fig:phd-halfnorm}
\end{figure}

Finally, plot the observed against expected absolute residuals as points, and add the lines for the confidence envelope,
producing \figref{fig:phd-halfnorm}.
<<phdpubs6-hnp, eval=FALSE>>=
plot(expected, observed,
     xlab = "Expected value of half-normal order statistic",
     ylab = "Absolute value of studentized residual")
lines(expected, mean, lty = 1, lwd = 2, col = "blue")
lines(expected, lower, lty = 2, lwd = 2, col = "red")
lines(expected, upper, lty = 2, lwd = 2, col = "red")
identify(expected, observed, labels = names(observed), n = 3)
@

The shape of the QQ plot in \figref{fig:phdpubs6-qqplot} shows a peculiar bend at low values
and the half-normal version in \figref{fig:phd-halfnorm} has a peculiar hump in the middle.
What could be the cause?

\figref{fig:phdpubs6-res-plots} shows two additional plots of the
studentized residuals that give a clear answer.  The density plot at the left shows a strongly bimodal
distribution of the residuals.  An additional plot at the right of residuals against the log(response)
confirms the guess that the lower mode corresponds to those students who published no articles---excess zeros again!

<<phdpubs6-res-plots, h=6, w=6, out.width='.5\\textwidth', cap='Further plots of studentized residuals. Left: density plot; right: residuals against log(articles+1).'>>=
# examine distribution of residuals
res <- rstudent(phd.nbin)
plot(density(res), lwd = 2, col = "blue",
     main = "Density of studentized residuals")
rug(res)

# why the bimodality?
plot(jitter(log(PhdPubs$articles + 1), factor = 1.5), res,
     xlab = "log (articles + 1)", ylab = "Studentized residual")
@
Now we have something to worry about that \emph{could} affect substantive interpretation or conclusions from this
analysis using the NB model, but not accounting for excess zeros.
If we believe, following \citet{Long:1997}, that there is a separate latent class of students who don't
publish, it would be sensible to fit a zero-inflated NB model, perhaps with a different subset of
predictors for the zero component.  The alternative theory of a ``hurdle'' to a first publication
suggests fitting a hurdle model.  We leave these as exercises for the reader.

\end{Example}
\ixoff{half-normal plot}
\ixoff{quantile--quantile (QQ) plots}
\ixoff{generalized linear model!diagnostic plots}
\ixoff{diagnostic plots}

\section{Multivariate response GLM models\hard}\label{sec:glm-multiv}
\ixon{generalized linear model!multivariate response}

\epigraph{Far better an approximate answer to the right question,
which is often vague, than an exact answer to the wrong question,
which can always be made precise.}{John W. Tukey \citeyearpar{Tukey:1962}, \emph{The future of data analysis}}

<<multiv, child='ch11/multiv.Rnw'>>=
@

<<nmes-multiv, child='ch11/nmes-multiv.Rnw'>>=
@
\ixoff{generalized linear model!multivariate response}

\ixoff{generalized linear model}

\section{Chapter summary}
\input{ch11/summary}

%\section{Further reading}

\section{Lab exercises}
<<exercises11, child="ch11/exercises.Rnw", purl=FALSE>>=
@


% Cleanup local variables
<<cleanup11, include=FALSE, purl=FALSE>>=
# detach(package:ggtern)  ## detach any masking packages
.locals$ch11 <- setdiff(ls(), .globals)
#.locals$ch11
remove(list=.locals$ch11[sapply(.locals$ch11,function(n){!is.function(get(n))})])
.pkgs$ch11 <- setdiff(.packages(), .base.pkgs)
@



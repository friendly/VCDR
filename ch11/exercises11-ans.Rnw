\begin{Exercises}

  \exercise \citet{Poole:1989} studied the mating behavior of elephants over 8 years in Amboseli National Park,
  Kenya. A focal aspect of the study concerned the mating success of males in relation to age, since larger
  males tend to be more successful in mating.  Her data were used by \citet[\C 22]{RamseySchafer:2002} 
  as a case study, and are contained in the \Rpackage{Sleuth2} \citep{Sleuth2} as \data{case2201}.

  For convenience, rename this to \code{elephants}, and study the relation between \code{Age} 
  (at the beginning of the study) and number of successful \code{Matings}
  for the 41 adult male elephants observed over the course of this study, ranging in age from 27--52.
<<elephants>>=
data("case2201", package="Sleuth2")
elephants <- case2201
str(elephants)
@
  \begin{enumerate*}
    \item Create some exploratory plots of \code{Matings} against \code{Age} in the styles illustrated in this chapter.
    To do this successfully, you will have to account for the fact that \code{Matings} has a range of only
    0--9, and use some smoothing methods to show the trend.
    \begin{ans}
    The simplest plot just jitters the number of matings, and draws a smoothed lowess curve.
    <<ex11_1a, echo=-1>>=
    op <- par(mar=c(4,4,1,1)+.1)
    with(elephants, {
    	plot(jitter(Matings) ~ Age)
    	lines(lowess(Age, Matings), lwd=2, col="red")}
    	)
    @

    \end{ans}
    
    \item Repeat (a) above, but now plotting \code{log(Matings+1)} against \code{Age} to approximate a
    Poisson regression with a log link and avoid problems with the zero counts.
    \begin{ans}
    As noted in the text, you can use \code{log="y"}, but then the Y variable should be used as Y+1 to
    avoid problems with 0 counts.
    <<ex11_1b, echo=-1>>=
    op <- par(mar=c(4,4,1,1)+.1)
    with(elephants, {
    	plot(jitter(Matings+1) ~ Age, log="y", ylab="log(Matings+1)")
    	lines(lowess(Age, Matings+1), lwd=2, col="red")}
    	)
    @
    \pkg{ggplot2} makes it easy to make a similar plot, and to also overlay the fit of a linear model.
    This also shows error bands for the loess and linear fits. 
    <<ex11_1b2>>=
    library(ggplot2)
    ggplot(elephants, aes(x=Age, y=Matings+1)) + 
      geom_jitter() +
    	geom_smooth(method="loess", color="red", size=2, fill="red", alpha=0.2) +
    	geom_smooth(method="lm", color="blue", size=2, fill="blue", alpha=0.2) +
    	scale_y_log10(breaks=c(1,2,5,10, 20)) + 
      theme_bw()
    @

    \end{ans}
    
    \item Fit a linear Poisson regression model for \code{Matings} against \code{Age}.  Interpret the
    fitted model \emph{verbally} from a graph of predicted number of matings and/or from the model
    coefficients. (\emph{Hint}: Using \code{Age-27} will make the intercept directly interpretable.)
    \begin{ans}
    \code{Age-27} shifts the value of intercept to the minimum value in the data. In a model formula,
    use \code{I(Age-27)}. The coefficient for \code{Age} then relates to increments in log(Matings);
    expontiating the coefficient give the multiple of Matings for a unit change in Age.
    <<ex11_1c>>=
    elephants.mod1 <- glm(Matings ~ I(Age-27), data=elephants, family=poisson)
    coef(elephants.mod1)
    exp(coef(elephants.mod1))
    @

    Thus, at Age 27, these elephants have a predicted 1.31 matings.  For each additional year,
    matings are expected to be multiplied by 1.07, an increase of 7\%.
    Perhaps the best way to visualize the model predictions are through an effect plot.

    <<ex11_1c2>>=
    plot(Effect("Age", elephants.mod1, 
                xlevels=list(Age=seq(25,50,5))))
    @
    
    \end{ans}
    
    \item Check for nonlinearity in the relationship by using the term \code{poly(Age,2)} in a new
    model.  What do you conclude?
    \begin{ans}
    There is little evidence for nonlinearity, as evidenced by a test of the quadratic model
    in Age, or by a plot of the predicted values under this model.
    <<ex11_1d>>=
    elephants.mod1q <- glm(Matings ~ poly(Age,2), data=elephants, family=poisson)
    anova(elephants.mod1, elephants.mod1q, test="Chisq")
    plot(allEffects(elephants.mod1q))
    @

    \end{ans}
    
    \item Assess whether there is any evidence of overdispersion in these data by fitting analogous
    quasi-Poisson and negative-binomial models.
    \begin{ans}
    The simple way to assess overdispersion is via \func{dispersiontest}, which is not significant here.
    A more careful answer would fit and compare the overdispersed models suggested.
    <<ex11_1e>>=
    dispersiontest(elephants.mod1)
    @

    \end{ans}
    
  \end{enumerate*}

  
  \exercise The data set \data{quine} in \pkg{MASS} gives data on absenteeism from schools in rural New South Wales, Australia.
   146 children were classified by ethnic background (\var{Eth}), age (\var{Age}, a factor), \var{Sex}, and 
   Learner status (\var{Lrn}),
   and the number of days absent (\var{Days}) from school
   in a particular school year was recorded.
   \begin{enumerate*}
    \item Fit the all main-effects model in the Poisson family and examine the tests of these effects using
    \func{summary} and \pkg{car}::\func{Anova}.  Are there any terms that should be dropped according to these tests?
    \begin{ans}
    For such a factorial design, a useful first step is to examine the sample sizes in the cells of this 4-way
    classification.  The table below shows that the design is very unbalanced, and that there are no slow learners
    (SL) in age F3.
    <<ex11_2a0>>=
    quine.tab <- xtabs(~ Lrn + Age + Sex + Eth, data=quine)
    ftable(Age + Sex ~ Lrn + Eth, data=quine.tab)
    @
    \var{Age} here corresponds to ``Form'', or grade in school, arguably an ordered factor, so we make it so.
    The Poisson model \func{Anova} shows that all terms are significant.  \func{summary} shows that the
    effects of \var{Age} have significant linear, quadratic and cubic trends.
    <<ex11_2a>>=
    data("quine", package="MASS")
    quine$Age <- ordered(quine$Age)
    quine.mod1 <- glm(Days ~ ., data=quine, family=poisson)
    Anova(quine.mod1)
    summary(quine.mod1)
    @
    Although not asked in the question, a careful analysis will try to understand the fitted model,
    e.g., via an effect plot.
    <<ex11_2a2, h=4, w=12, out.width='.9\\textwidth'>>=
    plot(allEffects(quine.mod1), rows=1, cols=4, ci.style='bands')
    @

    \end{ans}
    
    \item Re-fit this model as a quasi-Poisson model.  Is there evidence of overdispersion?
    Test for overdispersion formally, using \func{dispersiontest} from \pkg{AER}.
    \begin{ans}
    \func{dispersiontest} reveals very substantial overdispersion, with variance approximately
    $\widehat{\phi} =13.2$ times the mean under this model.
    <<ex11_2b>>=
    library(AER)
    dispersiontest(quine.mod1)
    quine.mod1q <- glm(Days ~ ., data=quine, family=quasipoisson)
    @

    \end{ans}
    
    \item Carry out the same significance tests and explain why the results differ from those 
    for the Poisson model.
    \begin{ans}
    The \func{Anova} tests for the quasi-Poisson model \code{quine.mod1q} show that only
    ethnicity and age have significant effects, learner status nearly so.
    Relative to the standard Poisson model, the coefficients are the same, but
    the standard errors have been adjusted by a factor of $\widehat{\phi} ^ {-1/2} = 0.28$
    <<ex11_2c>>=
    Anova(quine.mod1q)
    coeftest(quine.mod1q)
    @

    \end{ans}
    
   \end{enumerate*}

  \exercise The data set \data{AirCrash} in \pkg{vcdExtra} was analyzed in \labref{lab:mosaic-crash} and \labref{lab:ca-crash}
  in relation to the \var{Phase} of the flight and \var{Cause} of the crash.  Additional variables include the number of 
  \var{Fatalities} and \var{Year}.  How does \var{Fatalities} depend on the other variables?
  \begin{enumerate*}
    \item Use the methods of this chapter to make some exploratory plots relating fatalities to each of the predictors.
    \begin{ans}
    Both \var{Phase} and \var{Cause} are unordered factors, whose levels are ordered lexically.  For graphics and
    analysis it is useful to reorder \var{Phase} in temporal order.
    Plots of the total number fatalities over \var{Year}, in either jittered scatterplot or boxplot form show no
    overall trend.  (Other plots, not shown here, indicate that the number of crashes has decreased over time.)
    As in the text, we plot these on a log scale.
    <<ex11_3a, out.width='.49\\textwidth'>>=
    AirCrash$Phase <- factor(AirCrash$Phase,
    		levels=c("standing", "take-off", "en route", "landing", "unknown"))
    with(AirCrash, {
         plot(jitter(Fatalities+1) ~ Year, log="y",
              ylab = "log(Fatalities + 1)", cex.lab=1.25)
         lines(lowess(Year, Fatalities+1), col="blue", lwd=2)
    		})
    
    plot(Fatalities ~ cutfac(Year), data=AirCrash, log="y",
         ylab = "log(Fatalities)", xlab="Year (deciles)")
    @
    Plots of fatalities against the factors can be done in a variety of forms.  Here we use \pkg{ggplot2}
    for bar charts.  Note the use of \code{geom_bar(aes(weight=Fatalities))}, so that the height of each
    bar is proportional to the number of fatalities; otherwise, it would just show the number of crashes.
<<ex11_3a2, out.width='.49\\textwidth'>>=
ggplot(AirCrash, aes(Phase)) + geom_bar(aes(weight=Fatalities)) + 
      ylab("Fatalities") + theme_bw()
ggplot(AirCrash, aes(Cause)) + geom_bar(aes(weight=Fatalities)) + 
      ylab("Fatalities") + theme_bw()
@

    \end{ans}
    
    \item Fit a main effects poisson regression model for \var{Fatalities}, and make effects plots to visualize the model.
    Which phases and causes result in the largest number of fatalities?
    \begin{ans}
    <<ex11_3b>>=
    crash.mod1 <- glm(Fatalities ~ Phase + Cause + Year, 
                     data=AirCrash, family=poisson)
    Anova(crash.mod1)
    @
    From the marginal plots for part (a), it appears that most fatalities occur en route or on landing,
    and the primary cause is human error.  However, an effects plot for the main effects model,
    where other factors are controled in a given panel, tells a different story: Unknown phase rises
    to the top, and the greatest cause is criminal activity.  The plot for \var{Year} is slightly
    misleading, because the range is relatively small compared to the other panels.  This can be avoided
    by setting \code{ylim=log(c(1,180))} in the plot.
<<ex11_3b2, h=4, w=12, out.width='.9\\textwidth'>>=
plot(allEffects(crash.mod1), rows=1, cols=3)
@

    \end{ans}
    
    \item A linear effect of \var{Year} might not be appropriate for these data.  Try using a natural spline term,
    \code{ns(Year, df)} to achieve a better, more adequate model.
    \begin{ans}
    A careful analysis would investigate the tradeoff between goodness-of-fit and parsimony in the choice
    of degrees of freedom.  Here we just illustrate the use of \code{ns(Year,3)}, allowing 3 df for the
    \var{Year} effect.  This fits significantly better than the linear model in \var{Year}.
<<ex11_3c>>=
library(splines)
crash.mod2 <- glm(Fatalities ~ Phase + Cause + ns(Year,3), 
                 data=AirCrash, family=poisson)
anova(crash.mod1, crash.mod2, test="Chisq")
@

    \end{ans}
    
    \item Use a model-building tool like \func{add1} or \pkg{MASS}::\func{stepAIC} to investigate whether there
    are important two-way interactions among the factors and your chosen effect for \var{Year}.
    \begin{ans}
    We don't show a complete analysis here. \func{add1} just looks at each of the two-way interaction terms
    and reports that adding each one, separately, would decrease the deviance and AIC, resulting in a better-fitting
    model.  \func{stepAIC} eventually includes all three two-way terms.
    <<ex11_3d>>=
    add1(crash.mod2, scope= ~.^2, test="Chisq")
    # refit the stepAIC final model
    crash.modAIC <- update(crash.mod2, .~. + Phase:Cause + Phase:ns(Year, 3) + Cause:ns(Year, 3))
    Anova(crash.modAIC)
    @
    \end{ans}
    
    \item Visualize and interpret your final model and write a brief summary to answer the 
    question posed.
    \begin{ans}
    The number of fatalities in air crashes depends in a complex way on the combinations of
    \var{Phase}, \var{Cause} and \var{Year}.  We illustrate this below with an effect plot
    for the interaction of \var{Phase} and \var{Cause}, the interpretation of which just
    entails trying to describe the patterns in the plot.  
    <<ex11_3d2, h=7, w=8>>=
    plot(Effect(c("Phase", "Cause"), crash.modAIC), 
         multiline=TRUE, lwd=3, key.args=list(x=0.5, y=0.2))
    @

    \end{ans}
    
  \end{enumerate*}
  
% %% Incorporate this directly into the exercises after getting permission from Meagan to use the data
% <<lab-cormorants, child="ch11/cormorants.Rnw">>=
% @
  \exercise Male double-crested cormorants use advertising behavior to attract females for breeding.
	The \data{Cormorants} data set in \pkg{vcdExtra} gives some results from a study by
	Meagan Mc Rae \citeyearpar{McRae:2015} on counts of advertising males observed two or three times a week
	at six stations in a tree-nesting colony for an entire breeding season.
	The number of advertising birds was counted and these observations were classified
	by characteristics of the trees and nests. The goal was to determine how this behavior varies 
	temporally over the season and spatially over observation stations, as well as with 
	characteristics of nesting sites.
	The response variable is \var{count}
	and other predictors are shown below.  See \help{Cormorants, package="vcdExtra"}
	for further details.
<<cormorants, R.options=list(width=90)>>=
data("Cormorants", package = "vcdExtra")
car::some(Cormorants)
@
	\begin{enumerate*}
		\item Using the methods illustrated in this chapter, make some exploratory plots of the
		number of advertising birds against week in the breeding season, perhaps stratified
		by another predictor, like tree \var{height}, nest condition, or observation
		\var{station}. 
		To see anything reasonable,
		you should plot \var{count} on a log (or square root) scale, jitter the points, and add
		smoothed curves. The variable \var{category} breaks the weeks into portions of the
		breeding season, so adding vertical lines separating those will be helpful for interpretation.
		\begin{ans}
		Here we use \pkg{ggplot2} to plot \var{count} against \var{week}, stratified by \var{height}
		and \var{nest}.
		The plot for \var{height} shows that counts of advertising birds increase with height in the
		tree and rise over week at the end of the pre-breeding portion of the season.
    <<ex11_4a, h=6, w=6, out.width='.49\\textwidth'>>=
    my_theme <- theme_bw() + 
                theme(legend.position = c(0.8, 0.8),
                      legend.title = element_text(size=18),
                      legend.text = element_text(size=16))
    	 
    ggplot(Cormorants, aes(week, count, color=height)) + 
      geom_jitter() +
    	stat_smooth(method="loess", size=2) + 
    	scale_y_log10(breaks=c(1,2,5,10)) +
    	geom_vline(xintercept=c(4.5, 9.5)) +
    	my_theme
    
    ggplot(Cormorants, aes(week, count, color=nest)) + 
      geom_jitter() +
      stat_smooth(method="loess", size=2) + 
      scale_y_log10(breaks=c(1,2,5,10)) +
      geom_vline(xintercept=c(4.5, 9.5)) +
      my_theme
    @
		\end{ans}
		
		\item Fit a main-effects Poisson GLM to these data and test the terms using
		\func{Anova} from the \Rpackage{car}.
		\begin{ans}
		All terms except \code{tree\_health} show significant main effects.
    <<ex11_4b>>=
    fit1 <-glm(count ~ week + station + nest + height + density + tree_health, data=Cormorants,
        family =  poisson)
    library(car)
    Anova(fit1)
    @
		\end{ans}
		
		\item Interpret this model using an effects plot.
		\begin{ans}
		According to the linear model, counts (a) decrease over weeks in the seasons; (b)
		are greatest with no nests; (c) increase with height in the tree and
		(d) are greatest when the density is low.
    <<ex11_4c, h=5, w=9, out.width='.75\\textwidth'>>=
    library(effects)
    plot(allEffects(fit1))
    @
		\end{ans}
		
		\item Investigate whether the effect of \var{week} should be treated as linear in the
		model.  You could try using a polynomial term like \code{poly(week, degree)} or
		perhaps better, using a natural spline term like \code{ns(week, df)} from the \basepkg{splines} package.
		\begin{ans}
		Here we drop \var{tree\_health} and
		use a natural spline with 3 degrees of freedom for \var{week} to allow a moderate departure from linearity,
		roughly comparable to a cubic term \code{poly(week, 3)} in complexity.
		The effect plot for week shows a pronounced rise over the early weeks, followed by a steady decline over
		the rest of the season.
    <<ex11_4d>>=
    library(splines)
    fit2 <-glm(count ~ ns(week,3) + station + nest + height + density , data=Cormorants,
        family = poisson)
    Anova(fit2)
    plot(Effect("week", fit2))
    @
    A more thorough analysis would investigate whether there are important interactions among the model terms.
    The model below checks whether there are interactions of week with any of the other factors.
    The conclusion is no.
    <<ex11_4d2>>>=
    fit3 <- update(fit2, . ~ . + week * (station + nest + height + density))
    Anova(fit3)
    @
    
		\end{ans}
		
    \item 
    \begin{sloppypar} Test this model for overdispersion, using either a \code{quasipoisson} family or
    \func{dispersiontest} in \pkg{AER}. 
    \end{sloppypar}
    \begin{ans}
    Using \func{dispersiontest} on the \code{fit1} and \code{fit2} models shows significant overdispersion for
    the former, but not for the latter.  This illustrates that the test for overdispersion
    assumes that the model is correctly specified.
    <<ex11_4e>>=
    require(AER)
    dispersiontest(fit1)
    dispersiontest(fit2)
    @

    \end{ans}
    
	\end{enumerate*}		

  \exercise For the \data{CodParasites} data, recode the \code{area} variable as an ordered factor as suggested in
  footnote \ref{fn:russian}.  Test the hypotheses that prevalence and intensity of cod parasites is linearly
  related to area.
  \begin{ans}
  We illustrate this only for fitting the negative binomial model to the \var{intensity} variable,
  the count of parasites.
  The four areas A1--A4 are ordered from East to West, so the easiest way to do this test of linearity is
  to create a numeric equivalent.
  <<ex11_5a>>=
  data("CodParasites", package = "countreg")

  ## omit NAs in response
  CodParasites <- subset(CodParasites, !is.na(intensity))
  
  # make a numeric variable from area
  CodParasites$areaEW <- as.numeric(CodParasites$area)
  @
  Then, we fit negative binomial models with \var{area} as a factor, and \var{areaEW} as a numeric variable.
  <<ex11_5b>>=
  library(MASS)
  cp_nb     <- glm.nb(intensity ~ length + area * year, data = CodParasites)
  cp_nb_lin <- glm.nb(intensity ~ length + areaEW * year, data = CodParasites)
  Anova(cp_nb_lin)
  anova(cp_nb_lin, cp_nb, test="Chisq")
  @
  The model with area as a factor is significantly better than the model with only a linear
  effect.  Nonetheless, an effect plot shows that the intensity of parasites is greatest
  in the most eastern area, Varangerfjord (A4) in all three years, lending some credance
  to the ``Russian hypothesis.''
<<ex11_5c, h=4, w=12, out.width='.9\\textwidth'>>=
plot(Effect(c("area", "year"), cp_nb), layout=c(3,1))
@
  \end{ans}
  

  \exercise In \exref{ex:cod1}, we ignored other potential predictors in the \data{CodParasites} data:
  \code{depth}, \code{weight}, \code{length}, \code{sex}, \code{stage}, and \code{age}.
  Use some of the graphical methods shown in this case study to assess whether any of these are related
  to prevalence and intensity.
  \begin{ans}
  Prevalence, a factor corresponding to \code{intensity>0}, can be studied by simple plots, that
  are essentially spineplots. In these plots prevalence seems to vary with \var{depth} and
  \var{length}, but not with \var{weight} and \var{sex}.
  <<ex11_6a, h=8, w=12, out.width='.8\\textwidth' >>=
  CodParasites <- subset(CodParasites, sex !=0)
  CodParasites$sex <- factor(CodParasites$sex, labels=c("male", "female"))
  
  op <-par(mfrow = c(2, 2), mar=c(4,4,1,1)+.1)
  plot(prevalence ~ depth, data = CodParasites)
  plot(prevalence ~ weight, data = CodParasites)
  plot(prevalence ~ length, data = CodParasites)
  plot(prevalence ~ sex, data = CodParasites)
  par(op)
  @
  For intensity, the most informative plots use \pkg{ggplot2}, in the style of Figure 11.20.
  That is, plot jittered points, use a log scale for intensity, and overlay smoothed and
  linear fits.  Intensity increases slightly with depth and decreases with the length
  of the fish.
  <<ex11_6b, out.width='.49\\textwidth'>>=
  CPpos <- subset(CodParasites, intensity>0 & !is.na(length))
  ggplot(CPpos, aes(x=depth, y=intensity)) +
  	geom_jitter(position=position_jitter(height=.1), alpha=0.25) + 
  	geom_rug(position='jitter', sides='b') +
  	scale_y_log10(breaks=c(1,2,5,10,20,50,100, 200)) +
  	stat_smooth(method="loess", color="red", fill="red", size=2) +
  	stat_smooth(method="lm", size=1.5) + theme_bw() +
  	labs(y='intensity (log scale)')
  
  ggplot(CPpos, aes(x=length, y=intensity)) +
  	geom_jitter(position=position_jitter(height=.1), alpha=0.25) + 
  	geom_rug(position='jitter', sides='b') +
  	scale_y_log10(breaks=c(1,2,5,10,20,50,100, 200)) +
  	stat_smooth(method="loess", color="red", fill="red", size=2) +
  	stat_smooth(method="lm", size=1.5) + theme_bw() +
  	labs(y='intensity (log scale)')
  @

  \end{ans}
  

  \exercise The analysis of the \data{PhdPubs} data in the examples in this chapter were purposely left incomplete,
  going only as far as the negative binomial model.
  \begin{enumerate*}
    \item Fit the zero-inflated and hurdle models to this data set, considering whether the count component should
    be Poisson or negative-binomial, and whether the zero model should use all predictors or only a subset.
    Describe your conclusions from this analysis in a few sentences.
    \begin{ans}
    Here we fit the hurdle and zero-inflated models, both poisson and negative-binomial, using all predictors.
    By AIC, model \code{phd.znb} is best, but by BIC, the regular negative-binomial fares best.
    <<ex11_7a1>>=
    library(MASS)
    library(countreg)
    data("PhdPubs", package="vcdExtra")
    
    phd.nbin  <- glm.nb(articles ~ ., data=PhdPubs)
      # hurdle and zero-inflated
    phd.hp    <- hurdle(articles ~ ., data=PhdPubs, dist = "poisson")
    phd.hnb   <- hurdle(articles ~ ., data=PhdPubs, dist = "negbin")
    phd.zp    <- zeroinfl(articles ~ ., data=PhdPubs, dist = "poisson")
    phd.znb   <- zeroinfl(articles ~ ., data=PhdPubs, dist = "negbin")
    
    LRstats(phd.nbin, phd.hp, phd.hnb, phd.zp, phd.znb,  sortby="BIC")
    @
    Examine the zero-inflated negative-binomial model:
    <<ex11_7a2>>=
    summary(phd.znb)
    @
    This suggests a simpler model in which \var{mentor} is the only variable affecting the
    zero counts.  This model is preferable to the full model by both AIC and BIC.
    <<ex11_7a3>>=
    phd.znb1   <- zeroinfl(articles ~ .| mentor, data=PhdPubs, dist = "negbin")
    LRstats(phd.znb, phd.znb1)
    @

    \end{ans}
    
    \item Using the methods illustrated in this chapter, create some graphs summarizing the predicted counts
    and probabilities of zero counts for one of these models.
    \begin{ans}
As described in the text, effect plots for analogs of hurdle and zero-inflated models can only
be made by fitting and graphing separately the models for the zero and positive counts.
We use a logistic regression for the zero counts.
<<ex11_7b>>=
phd.zero <-  glm(articles==0 ~., data=PhdPubs, family = binomial)
Anova(phd.zero)
phd.nzero <- glm.nb(articles ~ ., data=PhdPubs, subset = articles > 0)
Anova(phd.nzero)
@
The effect of \var{mentor} is dramatic: as the number of publications by the mentor increases,
the probability that a student will publish zero articles declines markedly.
<<ex11_7b1>>=
plot(Effect("mentor", phd.zero))
@
For the positive count model, we plot only the significant effects of \var{female}, \var{kids5}, and
\var{mentor}.  All have clear interpretations:
the number of articles published is lower for females, decreases with the number of young children,
and increases with the number of articles published by the mentor.
<<ex11_7b2, h=4, w=12, out.width='.8\\textwidth'>>=
plot(allEffects(phd.nzero)[c(1,3,5)], rows=1, cols=3)
@

    \end{ans}
    
    \item For your chosen model, use some of the diagnostic plots of residuals and other measures shown in
    \secref{sec:glm-diag} to determine if your model solves any of the problems noted in \exref{ex:phdpubs5}
    and \exref{ex:phdpubs6}, and whether there are any problems that remain.
    \begin{ans}
    Unfortunately, the best graphic methods, from the \Rpackage{car} are unavailable for hurdle and
    zero-inflated models.  A suitable alternative is to use diagnostic plots for separate models for
    the zero (\code{phd.zero}) and positive counts (\code{phd.nzero}).
    Plots for the zero count component are not particularly remarkable for a logistic regression model.
    <<ex11_7c1, h=5, w=10, out.width='.9\\textwidth'>>=
    op <- par(mfrow=c(1,2), mar=c(4,4,1,1)+.1)
    residualPlot(phd.zero, type="rstandard",
                 quadratic=TRUE, col.smooth="red", col.quad="blue",  id.n=3)
    
    residualPlot(phd.zero, "mentor", type="rstandard",
                 quadratic=TRUE, col.smooth="red", col.quad="blue",  id.n=3)
    par(op)
    @
    Similar plots for the positive count model (\code{phd.n zero}) would be done similarly, and
    are not particularly remarkable, except that they nominate some large positive residuals
    as unusual.
    
    An influence plot suggests that three cases should be given further scrutiny.

    <<ex_11_7c2, echo=-1>>=
    op <- par(mar=c(4,4,1,1)+.1)
    influencePlot(phd.nzero)
    @

    
    \end{ans}
    
  \end{enumerate*}

  \exercise In \exref{ex:nmes4} we used a simple analysis of $\log(\vec{y}+1)$ for the multivariate responses
  in the \data{NMES1988} data using a classical MLM (\eqref{eq:mlm})
  as a rough approximation of a multivariate Poisson model.
  The HE plot in \figref{fig:nmes4-hepairs} was given as a visual summary, but did not show the data.
  Examine why the MLM is not appropriate statistically for these data, as follows:
  \begin{enumerate*}
    \item Calculate residuals for the model \code{nmes.mlm} using
		<<eval=FALSE>>=
		resids <- residuals(nmes.mlm, type="deviance")
		@
    \begin{ans}
    This just copies the code from the text to fit the model and calculate the residuals:
    <<ex11_8a>>=
    data("NMES1988", package="AER")
    nmes2 <- NMES1988[, c(1:4, 6:8, 13, 15, 18)]
    
    clog <- function(x) log(x+1)
    nmes.mlm <- lm(clog(cbind(visits, nvisits, ovisits, novisits)) ~ ., data=nmes2)
    resids <- residuals(nmes.mlm, type="deviance")
    @
    \end{ans}
		
    \item Make univariate density plots of these residuals to show their univariate distributions.
    These should be approximately normal under the MLM.  What do you conclude?
    \begin{ans}
    There are a variety of ways to produce density plots in \R, but the simplest for this question is
    just to use \func{density} with default settings.
    The residuals for \code{visits} are reasonably symmetric.  All the others are quite positively
    skewed.
    <<ex11_8b, h=8, w=12, out.width='.6\\textwidth'>>=
    op <- par(mfrow=c(2,2), mar=c(5,4,2,1)+0.1)
    plot(density(resids[,1]), main = "Residuals for visits")
    rug(resids[,1])
    
    plot(density(resids[,2]), main = "Residuals for nvisits")
    rug(resids[,2])
    
    plot(density(resids[,3]), main = "Residuals for ovisits")
    rug(resids[,3])
    
    plot(density(resids[,4]), main = "Residuals for novisits")
    rug(resids[,4])
    par(op)
    @

    \end{ans}
    
    \item Make some bivariate plots of these residuals. Under the MLM, each should be bivariate normal
    with elliptical contours and linear regressions. Add 2D density contours
    (\func{kde2d}, or \func{geom\_density2d} in \pkg{ggplot2}) and some smoothed curve.
     What do you conclude?
     \begin{ans}
     Here is just one example for the first two variables, \var{visits}, and \var{nvisits}.
     The bivariate distribution is very far from bivariate normal, largely because
     \var{nvisits} is so positively skewed.  All other pairs of the residuals would be worse.
    <<ex11_8c, out.width='.6\\textwidth'>>=
    ggplot(as.data.frame(resids), aes(x=visits, y=nvisits)) +
    	geom_point(size=0.6) + ylim(c(-2, 3)) +
    	stat_smooth(method="lm") +
    	geom_density2d(size=1.25) + theme_bw()
    @
    The overall conclusion is that, while \figref{fig:nmes4-hepairs} in the text gives a useful
    overall summary of the relationship among the multivariate resonses, it should only be
    considered as a rough approximation.
    For comparison, the plot above corresponds to the error ellipse in the (2,1) panel of
    \figref{fig:nmes4-hepairs}, shown in red in the plot below.
    <<ex11_8c2>>=
    library(heplots)
    heplot(nmes.mlm, variables=1:2, fill=c(TRUE, FALSE))
    @

     \end{ans}
     

  \end{enumerate*}

\end{Exercises}

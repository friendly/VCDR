<<echo=FALSE>>=
source("Rprofile.R")
knitrSet("ch02")
#knitrSet("ch02", cache=TRUE)
require(vcdExtra, quietly = TRUE, warn.conflicts = FALSE)  # should go in Rprofile
.locals$ch02 <- NULL
.pkgs$ch02 <- NULL
@


\chapter{Working with Categorical Data}\label{ch:working}
\input{front/vtoc02}   %% visual contents images

\chapterprelude{%
Creating and manipulating categorical data sets requires
some skills and techniques in \R beyond those ordinarily used
for quantitative data. This chapter illustrates these for the
main formats for categorical data: case form, frequency form
and table form.
}

% \DONE{DM: The chapter does not cover NA handling, although this is needed
%   in some chapters. Maybe treat this in the also missing section on
%   subsetting? --- The note for \code{table} and in the subsetting
%   section should suffice.}

Categorical data can be represented as data sets
in various formats:
case form, frequency form, and table form.  This chapter
describes and illustrates the skills and techniques in \R
needed to input, create and manipulate \R data objects
to represent categorical data, and convert these from one
form to another for the purposes of statistical analysis
and visualization which are the subject of the remainder of the book.

As mentioned earlier, this book assumes that you have at least a
basic knowledge of the \R language and environment, including
interacting with the \R console (Rgui for Windows, R.app for Mac OS X)
or some other editor/environment (e.g., R Studio),
loading and using \R functions in packages (e.g., \code{library(vcd)})
getting help for these from \R (e.g., \code{help(matrix)}), etc.
This chapter is therefore devoted
to covering those topics needed in the book
beyond such basic skills.%
\footnote{
Some excellent introductory treatments of \R are:
\citet[\C 2]{FoxWeisberg:2011}, 
\citet{Maindonald+Braun:2007} and
\citet{Dalgaard:2008}.
Tom Short's \emph{R Reference Card}, \url{http://cran.us.r-project.org/doc/contrib/Short-refcard.pdf} is a handy 4-page summary of the main functions.
The web sites
Quick-R \url{http://www.statmethods.net/} and
Cookbook for R \url{http://www.cookbook-r.com/}
provide very helpful examples, organized by topics and tasks.
}


\section{Working with \R data: vectors, matrices, arrays and data frames}\label{sec:Rdata}

\R has a wide variety of data structures for storing, manipulating and
calculating with data.  Among these, vectors, matrices, arrays and
data frames are most important for the material in this book.

In \R, a \term{vector} is a collection of values, like numbers,
character strings, or logicals (\code{TRUE, FALSE}), and often correspond to a variable in some analysis.
Matrices are rectangular arrays like a traditional table, composed of vectors in their columns
or rows.
Arrays add additional dimensions, so that, for example, a 3-way table can be represented
as composed of rows, columns and layers.
An important consideration is that the values in vectors,
matrices and arrays must all be of the same \emph{mode}, e.g., numbers or character strings.
A \term{data frame} is a rectangular table, like a traditional data set in other
statistical environments, and composed of rows and columns like a matrix,
but allowing variables (columns) of different types. These data structures and the types of
data they can contain are illustrated in \figref{fig:datatypes}. A more general
data structure is a \emph{list}, a generic vector which can contain
any other types of objects (including lists, allowing for \emph{recursive}
data structures). A data frame is basically a list of equally-sized
vectors, each representing a column of the data frame.

\begin{figure}
\includegraphics[width=\textwidth]{ch02/fig/datatypes2}
\caption[Principal data structures and data types in R]{Principal data structures and data types in \R. Colors
 represent different data types: numeric, character, logical. }
\label{fig:datatypes}
\end{figure}

%\TODO{Delete subsections on vectors, matrices and arrays?}
<<vectors-matrices, child="ch02/basic.Rnw">>=
@

\subsection{data frames}\label{sec:data-frames}
Data frames are the most commonly used form of data in \R and more
general than matrices in that they can contain columns of different types.
For statistical modeling, data frames play a special role, in that
many modeling functions are designed to take a data frame as a
\code{data=} argument, and then find the variables mentioned within
that data frame. Another distinguishing feature is that discrete variables
(columns) like character strings \code{("M", "F")} or integers \code{(1, 2, 3)}
in data frames can be represented as \term{factor}s, which simplifies
many statistical and graphical methods.

A data frame can be created using keyboard input
with the \func{data.frame} function, applied to a list of objects,
\code{data.frame(a, b, c, ...)}, each of which can be a vector, matrix or another
data frame, but typically all containing the same number of rows.
This works roughly like \func{cbind}, collecting the arguments as columns
in the result.

The following example generates \code{n = 100} random observations on
three discrete factor variables, \code{A, B, sex}, and a numeric
variable, \code{age}.  As constructed, all of these are
statistically independent, since none depends on any of the others.
The function \func{sample}
is used here to generate \code{n} random samples from the
first argument allowing replacement (\code{replace = TRUE}).
The \func{rnorm} function produces a vector of \code{n} normally
distributed values with mean 30 and standard deviation 5.
The call to \func{set.seed} guarantees the reproducibility of the
resulting data. 
Finally, all four variables are combined into the data frame
\code{mydata}.


<<dataframe1>>=
set.seed(12345)   # reproducibility
n <- 100
A <- factor(sample(c("a1", "a2"), n, replace = TRUE))
B <- factor(sample(c("b1", "b2"), n, replace = TRUE))
sex <- factor(sample(c("M", "F"), n, replace = TRUE))
age <- round(rnorm(n, mean = 30, sd = 5))
mydata <- data.frame(A, B, sex, age)
head(mydata, 5)
str(mydata)
@

Rows, columns and individual values in a data frame can be manipulated
in the same way as a matrix. Additionally, variables can be extracted
using the \code{$} operator:

<<dataframe2>>=
mydata[1,2]
mydata$sex
##same as: mydata[,"sex"] or mydata[,3]
@ 
\noindent Values in data frames can conveniently be edited using,
e.g., \code{fix(mydata)}, opening a simple, spreadsheet-like editor.

For real data sets, it is usually most convenient to read these into \R
from external files, and this is easiest using plain text (ASCII) files
with one line per observation and fields separated by commas (or tabs),
and with a first header line giving the variable names-- called
\emph{comma-separated} or CSV format.
If your data is in the form of Excel, SAS, SPSS or other file format,
you can almost always export that data to CSV format first.%
\footnote{
The \Rpackage{foreign} contains specialized functions to \emph{directly} read
data stored by Minitab, SAS, SPSS, Stata, Systat and other software.
There are also a number of packages for reading (and writing)
Excel spreadsheets directly (\pkg{gdata}, \pkg{XLConnect}, \pkg{xlsx}).
The \R manual, \emph{R Data Import/Export} covers many other variations,
including data in relational data bases.
}

The function \func{read.table} has many options to control the details
of how the data are read and converted to variables in the data frame.
Among these some important options are:
\begin{description*}
  \item [\code{header}] indicates whether the first line contains
variable names. The default is \code{FALSE} unless the first line contains one fewer field
than the number of columns;
  \item[\code{sep}] (default: \code{""} meaning white space, i.e., one or more spaces, tabs or newlines) specifies the separator character between fields;
  \item[\code{stringsAsFactors}] (default: \code{TRUE}) determines whether character string variables should be converted to factors;
  \item[\code{na.strings}] (default: \code{"NA"}) one or more strings which are interpreted
  as missing data values (\code{NA});
\end{description*}
For delimited files, \func{read.csv} and \func{read.delim} are convenient wrappers
to \func{read.table}, with default values \code{sep=","} and \code{sep="\textbackslash t"} 
respectively, and
\code{header=TRUE}.

\begin{Example}[ch2-arth-csv]{Arthritis treatment}

The file \code{Arthritis.csv} contains data in CSV format
from \citet{KochEdwards:88}, representing
a double-blind clinical trial investigating a new treatment for rheumatoid arthritis with 84 patients.%
\footnote{This data set can be created using: \code{library(vcd);} \code{write.table(Arthritis, file = "Arthritis.csv", quote = FALSE, sep = ",")} }
The first (``header'') line gives the variable names.  Some of the
lines in the file are shown below, with \code{...} representing omitted lines:
{\small
\renewcommand{\baselinestretch}{.85}
%<<arth-csv, eval=FALSE, results='asis'>>=
\begin{verbatim}
ID,Treatment,Sex,Age,Improved
57,Treated,Male,27,Some
46,Treated,Male,29,None
77,Treated,Male,30,None
17,Treated,Male,32,Marked
 ...
42,Placebo,Female,66,None
15,Placebo,Female,66,Some
71,Placebo,Female,68,Some
1,Placebo,Female,74,Marked
\end{verbatim}
%@
}

%\DONE{DM: Add this to vcd or vcdExtra. --- added footnote.}

We read this into \R using \func{read.table} as shown below:
<<arth-read1, size="footnotesize">>=
path <- "ch02/Arthritis.csv" ## set path
## for convenience, use path <- file.choose() to retrieve a path 
## then, use file.show(path) to inspect the data format
Arthritis <- read.table(path, header = TRUE, sep = ",")
str(Arthritis)
@
Note that the character variables \var{Treatment}, \var{Sex} and \var{Improved}
were converted to factors, and the levels of those variables were
ordered \emph{alphabetically}.  This often doesn't matter much for binary variables,
but here, the response variable \var{Improved} has levels
that should be considered \emph{ordered},
as \code{"None", "Some", "Marked"}.  We can correct this here by
re-assigning \code{Arthritis$Improved} using \func{ordered}.
The topic of re-ordering variables and levels in categorical data is
considered in more detail in \secref{sec:ordered}.

<<arth-read2>>=
levels(Arthritis$Improved)
Arthritis$Improved <- ordered(Arthritis$Improved,
                              levels = c("None", "Some", "Marked"))
@

\end{Example}

\section{Forms of categorical data: case form, frequency form and table form}\label{sec:forms}
As we saw in \chref{ch:intro}, categorical data can be represented as ordinary data sets
in case form, but the discrete nature of factors or stratifying variables allows the same
information to be represented more compactly in summarized form with a frequency
variable for each cell of factor combinations, or in tables.
Consequently, we sometimes
find data created or presented in one form (e.g., a spreadsheet data set, a two-way
table of frequencies) and want to input that into \R.  Once we have the data in \R,
it is often necessary to manipulate the data into some other form for the purposes
of statistical analysis, visualizing results and our own presentation.
It is useful to understand the three main forms of categorical data in \R and how
to work with them for our purposes.

\subsection{Case form}
Categorical data in case form are simply data frames, with one or more discrete
classifying variables or response variables, most conveniently represented as factors or ordered factors.  In case form, the data set can also contain numeric variables
(covariates or other response variables), that cannot be accommodated in other
forms.

As with any data frame, \code{X}, you can access or compute with its attributes using \code{nrow(X)} for the number of observations,
\code{ncol(X)} for the number of variables,
\code{names(X)} or \code{colnames(X)} for the variable names and
so forth.

\begin{Example}[ch2-arth]{Arthritis treatment}
<<arth-setup, echo=FALSE>>=
data("Arthritis", package = "vcd")
@
The \data{Arthritis} data is available in case form in the \pkg{vcd} package.
There are two explanatory factors: \code{Treatment} and \code{Sex}. \code{Age}
is a numeric covariate, and \code{Improved} is the response---an ordered factor,
with levels
%\code{\Sexpr{paste(levels(Arthritis$Improved),collapse=' < ')}}.
\code{"None" < "Some" < "Marked"}. Excluding \code{Age}, we would have
a $2 \times 2 \times 3$ contingency table for \code{Treatment}, \code{Sex} and \code{Improved}.
<<case-form,size="footnotesize">>=
data("Arthritis", package = "vcd")  # load the data
names(Arthritis)      # show the variables
str(Arthritis)        # show the structure
head(Arthritis, 5)    # first 5 observations, same as Arthritis[1:5,]
@
\end{Example}

\subsection{Frequency form}
Data in frequency form is also a data frame, containing
one or more discrete factor variables and a frequency variable
(often called \code{Freq} or \code{count})
representing the number of basic observations in that cell.

This is an alternative representation of a table form data set considered
below.
In frequency form, the number of cells in the equivalent table
is \code{nrow(X)}, and the total number of observations
is the sum of the frequency variable, \code{sum(X$Freq)}, %$
 \code{sum(X[,"Freq"])} or a similar expression.

\begin{Example}[ch2-GSS]{General social survey}
For small frequency tables, it is often convenient to enter them in frequency form
using \func{expand.grid} for the factors and \func{c} to list the counts in a vector.
The example below, from \cite{Agresti:2002} gives results for the 1991 General Social Survey,
with respondents classified by sex and party identification.
As a table, the data look like this:
\begin{center}
\begin{tabular}{rrrr}
  \hline
    &     & party & \\
  \hline
sex & dem & indep & rep \\
  \hline
female & 279 & 73 & 225 \\
  male & 165 & 47 & 191 \\
   \hline
\end{tabular}
\end{center}

<<GSS-data, echo=FALSE, include=FALSE>>=
tmp <- expand.grid(sex = c("female", "male"),
                   party = c("dem", "indep", "rep"))
GSS <- data.frame(tmp, count = c(279, 165, 73, 47, 225, 191))
xtabs(count~sex+party, data=GSS)
@
We use \func{expand.grid} to create a $6 \times 2$ matrix
containing the combinations of \code{sex} and \code{party}
with the levels for \code{sex} given first, so that this varies
most rapidly. Then,
input the frequencies in the table by columns from
left to right, and combine these two results with
\func{data.frame}.
<<frequency-form,results='markup'>>=
# Agresti (2002), table 3.11, p. 106
tmp <- expand.grid(sex = c("female", "male"),
                   party = c("dem", "indep", "rep"))
tmp

GSS <- data.frame(tmp, count = c(279, 165, 73, 47, 225, 191))
GSS
names(GSS)
str(GSS)
sum(GSS$count)
@
The last line above shows that there are \Sexpr{sum(GSS$count)} %$
cases represented in the frequency table.
\end{Example}

\subsection{Table form}
Table form data is represented as a matrix, array or table object
whose elements are the frequencies in an $n$-way table.
The number of dimensions of the table is the length,
\code{length(dim(X))}, of its
\code{dim} (or \code{dimnames}) attribute, and the sizes of the
dimensions in the table are the elements of \code{dim(X)}.
The total number of observations represented is the sum of
all the frequencies, \code{sum(X)}.

\begin{Example}[ch2-hec]{Hair color and eye color}
A classic data set on frequencies of hair color, eye color and
sex is given in table form in \data{HairEyeColor} in the
\basepkg{datasets} package, reporting the frequencies of these
categories for \code{\Sexpr{sum(HairEyeColor)}} students in
a statistics course.
<<table-form1>>=
data("HairEyeColor", package = "datasets")    # load the data
str(HairEyeColor)                # show the structure
dim(HairEyeColor)                # table dimension sizes
dimnames(HairEyeColor)           # variable and level names
sum(HairEyeColor)                # number of cases
@
Three-way (and higher-way) tables can be printed in a more convenient
form using \func{structable} and \func{ftable} as described below
in \secref{sec:structable}.
\end{Example}

Tables are often created from raw data in case form or frequency form using the
functions \func{table} and \func{xtabs} described in \secref{sec:table}.
For smallish frequency tables that are already in tabular form, you can enter
the frequencies in a matrix, and then assign \code{dimnames} and other attributes.

To illustrate, we create the GSS data as a table below, entering the
values in the table by rows (\code{byrow=TRUE}), as they appear in
printed form.

<<table-form2>>=
GSS.tab <- matrix(c(279, 73, 225,
                    165, 47, 191), 
		  nrow = 2, ncol = 3, byrow = TRUE)
dimnames(GSS.tab) <- list(sex = c("female", "male"),
                          party = c("dem", "indep", "rep"))
GSS.tab
@
\code{GSS.tab} is a matrix, not an object of \code{class("table")}, and some functions
are happier with tables than matrices.%
\footnote{
There are quite a few functions in \R with specialized methods for
\class{table} objects. For example, \code{plot(GSS.tab)} gives a mosaic
plot and \code{barchart(GSS.tab)} gives a divided bar chart.
}
You should therefore coerce it to a table with \func{as.table},
<<table-form3>>=
GSS.tab <- as.table(GSS.tab)
str(GSS.tab)
@

\begin{Example}[jobsat1]{Job satisfaction}
Here is another similar example, entering data on job satisfaction
classified by \code{income} and level of \code{satisfaction}
from a $4 \times 4$ table given by \citet[Table 2.8, p. 57]{Agresti:2002}.
<<table-form4>>=
## A 4 x 4 table  Agresti (2002, Table 2.8, p. 57) Job Satisfaction
JobSat <- matrix(c(1, 2, 1, 0,
                   3, 3, 6, 1,
                   10, 10, 14, 9,
                   6, 7, 12, 11), 
		  nrow = 4, ncol = 4)
dimnames(JobSat) <- 
  list(income = c("< 15k", "15-25k", "25-40k", "> 40k"),
       satisfaction = c("VeryD", "LittleD", "ModerateS", "VeryS"))
JobSat <- as.table(JobSat)
JobSat
@
\end{Example}

\section{Ordered factors and reordered tables}\label{sec:ordered}
As we saw above (\exref{ex:ch2-arth-csv}), the levels of factor variables in
data frames (case form or frequency form)
can be re-ordered (and the variables 
declared as ordered factors) using \func{ordered}.
As well, the order of the factor values themselves can be rearranged by
sorting the data frame using \func{sort}.

However, in table form, the values of the table factors are ordered by their position in the table.
Thus in the \data{JobSat} data, both \var{income} and \var{satisfaction} represent ordered
factors, and the \emph{positions} of the values in the rows and columns reflects their
ordered nature, but only implicitly.

Yet, for analysis or graphing, there are occasions when you need \emph{numeric} values for the levels
of ordered factors in a table, e.g., to treat a factor as a quantitative variable.
In such cases, you can simply re-assign the \code{dimnames} attribute of the table
variables.  For example, here, we assign numeric values to \code{income} as the middle of their
ranges, and treat \code{satisfaction} as equally spaced with integer scores.

<<relevel1,results='hide',eval=FALSE>>=
dimnames(JobSat)$income <- c(7.5, 20, 32.5, 60)
dimnames(JobSat)$satisfaction <- 1:4
@

A related case is when you want to preserve the character labels of table dimensions,
but also allow them to be sorted in some particular order. A simple way to do this
is to prefix each label with an integer index using \func{paste}.

<<relevel2,results='hide',eval=FALSE>>=
dimnames(JobSat)$income <- 
    paste(1:4, dimnames(JobSat)$income, sep = ":")
dimnames(JobSat)$satisfaction <-
    paste(1:4, dimnames(JobSat)$satisfaction, sep = ":")
@

A different situation arises with tables where you want to \emph{permute} the levels
of one or more variables to arrange them in a more convenient order without changing
their labels. For example, in the \data{HairEyeColor} table, hair color and eye color are ordered arbitrarily.
For visualizing the data using mosaic plots and other methods described later, it
turns out to be more useful to assure that both hair color and eye color are
ordered from dark to light.
Hair colors are actually ordered this way already:
\code{"Black", "Brown", "Red", "Blond"}.
But eye colors are ordered as \code{"Brown", "Blue", "Hazel", "Green"}.
It is easiest to re-order the
eye colors by indexing the columns (dimension 2) in this array to a new order,
\code{"Brown", "Hazel", "Green", "Blue"}, giving the
indices of the old levels in the new order (here: 1,3,4,2).
Again \func{str} is your friend, showing the structure of the result
to check that the result is what you want.

<<reorder1>>=
data("HairEyeColor", package = "datasets")
HEC <- HairEyeColor[, c(1, 3, 4, 2), ]
str(HEC)
@
%This is also the order for both hair color and eye color shown in
%the result of a correspondence analysis (\figref{fig:ca-haireye}) below.

Finally, there are situations where, particularly for display purposes, you
want to re-order the \emph{dimensions} of an $n$-way table, and/or change the
labels for the variables or levels.
This is easy when the data are in table form: \func{aperm} permutes
the dimensions, and assigning to \code{names} and \code{dimnames}
changes variable names and level labels respectively.

<<reorder3>>=
str(UCBAdmissions)
# vary along the 2nd, 1st, and 3rd dimension in UCBAdmissions
UCB <- aperm(UCBAdmissions, c(2, 1, 3))    
dimnames(UCB)$Admit <- c("Yes", "No")
names(dimnames(UCB)) <- c("Sex", "Admitted", "Department")
str(UCB)
@


\section[Generating tables: table and xtabs]{Generating tables with \func{table} and \func{xtabs}}\label{sec:table}

With data in case form or frequency form,
you  can  generate frequency  tables from factor variables in data frames
using the  \func{table} function; for  tables  of
proportions,  use  the \func{prop.table} function,  and for marginal  frequencies
(summing over some variables) use \func{margin.table}.  The examples below
use the same case-form data frame \code{mydata} used earlier (\secref{sec:data-frames}).

<<table1>>=
set.seed(12345)   # reproducibility
n <- 100
A <- factor(sample(c("a1", "a2"), n, replace = TRUE))
B <- factor(sample(c("b1", "b2"), n, replace = TRUE))
sex <- factor(sample(c("M", "F"), n, replace = TRUE))
age <- round(rnorm(n, mean = 30, sd = 5))
mydata <- data.frame(A, B, sex, age)
@

\subsection[table()]{\func{table}}\label{sec:table2}

\code{table(\dots)} takes a list of variables interpreted as factors,
\ixfunc{table}
or a data frame whose columns are so interpreted.
It does not take a \code{data=} argument, so either supply the
names of columns in the data frame (possibly using \func{with} for convenience), 
or select the variables using column indexes:
<<table-ex1>>=
# 2-Way Frequency Table
table(mydata$A, mydata$B)           # A will be rows, B will be columns
## same: with(mydata, table(A, B))
(mytab <- table(mydata[,1:2]))      # same
@

We can use \code{margin.table(X, margin)} to sum a table \code{X} for
the indices in \code{margin}, i.e., over the dimensions not included
in \code{margin}.
A related function is \code{addmargins(X, margin, FUN = sum)},
\ixfunc{margin.table}
\ixfunc{addmargins}
which extends the dimensions of a table or array with the marginal values calculated
by \code{FUN}.

<<table-ex2>>=
margin.table(mytab)      # sum over A & B
margin.table(mytab, 1)   # A frequencies (summed over B)
margin.table(mytab, 2)   # B frequencies (summed over A)
addmargins(mytab)        # show all marginal totals
@
The function \func{prop.table} expresses the table entries as a fraction of
a given marginal table.
<<table-ex2a>>=
prop.table(mytab)        # cell proportions
prop.table(mytab, 1)     # row proportions
prop.table(mytab, 2)     # column proportions
@

\func{table} can  also  generate  multidimensional  tables  based  on  3  or  more
categorical variables. In  this case, use  the \func{ftable}  or \func{structable}
function to print the
results more attractively as a ``flat'' (2-way) table.

% \TODO{DM: is there any advantage of ftable() over structable()? I
%   think not, so just use structable()?}

<<table-ex3>>=
# 3-Way Frequency Table
mytab <- table(mydata[,c("A", "B", "sex")])
ftable(mytab)
@
\func{table}  ignores missing values by default, but has optional arguments
\code{useNA} and \code{exclude} that can be used to control this.
See \code{help(table)} for the details.

\subsection[xtabs()]{\func{xtabs}}\label{sec:xtabs}

The \func{xtabs} function allows you to create cross tabulations of data using formula style input.
This typically works with case-form or frequency-form data
supplied in a data frame or a matrix.
The result is a contingency table in array format, whose dimensions are determined by the terms on the right side of the formula.  As shown below, the \code{summary} method
for tables produces a simple $\chi^2$ test of independence of all
factors, and indicates the number of cases and dimensions.

<<xtabs-ex1>>=
# 3-Way Frequency Table
mytable <- xtabs(~ A + B + sex, data = mydata)
ftable(mytable)    # print table
summary(mytable)   # chi-squared test of independence
@

When the data have already been tabulated in frequency form, include the
frequency variable (usually \code{count} or \code{Freq})
on the left side of the formula, as shown in the example below for the GSS data.

<<xtabs-ex2,results='markup'>>=
(GSStab <- xtabs(count ~ sex + party, data = GSS))
summary(GSStab)
@

For \class{table} objects, the \code{plot} method produces basic mosaic plots
using the \func{mosaicplot} function from the \basepkg{graphics} package. 

% With the option \code{shade=TRUE}, the
% cells are shaded according to the deviations (residuals) from an independence model.
% Mosaic plot are discussed in detail in \chref{ch:mosaic}.

% <<plot-xtab, out.width=".48\\textwidth", fig.cap="Mosaic plot of tables using the plot method for table objects">>=
% plot(mytable)
% plot(GSStab, shade=TRUE)
% @

\section[Printing tables: structable and ftable]{Printing tables with \func{structable} and \func{ftable}}\label{sec:structable}

\subsection{Text output}

For 3-way and larger tables, the functions
\func{ftable} (in the \basepkg{stats} package) and
\func{structable} (in \pkg{vcd}) provide a convenient and flexible tabular display in a ``flat'' (2-way) format.

With \code{ftable(X, row.vars=, col.vars=)}, variables assigned to the rows and/or columns of the result
can be specified as the integer numbers or character names of the variables in
the array \code{X}. By default, the last variable is used for the columns.
The formula method, in the form \verb|ftable(colvars ~ rowvars, data)|
allows a formula, where the left and right hand side of formula specify the column and row variables respectively.

<<ftable1>>=
 ftable(UCB)                      # default
#ftable(UCB, row.vars = 1:2)      # same result
 ftable(Admitted + Sex ~ Department, data = UCB)   # formula method
@

The \func{structable} function is similar, but more general, and uses
recursive splits in the vertical or horizontal directions
(similar to the construction of mosaic displays).  It works with both
data frames and table objects.
<<structable>>=
library(vcd)
structable(HairEyeColor)                   # show the table: default
structable(Hair + Sex ~ Eye, HairEyeColor) # specify col ~ row variables
@
It also returns an object of class \code{"structable"} for which there are a
variety of special methods.  For example, the transpose function \func{t}
interchanges rows and columns, so that a call like \code{t(structable(HairEyeColor))}
produces the second result shown just above.
%\class{structable} objects can be subset using the
%\code{[} and \code{[[} operators, using either level indices or names.
There are also plot methods: for example, \func{plot} produces mosaic plots from the
\pkg{vcd} package.

\section[Subsetting data]{Subsetting data}\label{sec:subsettingdata}

Often, the analysis of some data set is focused on a subset only. For
example, the \data{HairEyeColor} data set introduced above tabulates frequencies of hair and
eye colors for male and female students---the analysis could
concentrate on one group only, or compare both groups in a stratified
analysis. This section deals with extracting subsets of data in
tables, structables or data frames.

\subsection[Subsetting tables]{Subsetting tables}\label{sec:subsettingtables}

If data are available in tabular form created with \func{table} or
\func{xtabs}, resulting in \code{table} objects, subsetting is done
via indexing, either with integers or character strings corresponding to
the factor levels. The following code extracts the female data from
the \code{HairEyeColor} data set:

<<subset1>>=
HairEyeColor[,,"Female"]
##same using index: HairEyeColor[,,2]
@ 

\noindent Empty indices stand for taking all data of the corresponding
dimension. The third one (Sex) is fixed at the second (``\code{Female}'') 
level. Note that in this case, the dimensionality is reduced to a two-way
table, since dimensions with only one level are dropped by
default. Functions like \func{apply} can iterate through all levels of
one or several dimensions and apply a function to each subset. The
following calculates the total amount of male and female students:

<<subset2>>=
apply(HairEyeColor, 3, sum)
@ 

It is of course possible to select more than one level:

<<subset3>>=
HairEyeColor[c("Black", "Brown"), c("Hazel", "Green"),]
@ 

\subsection[Subsetting structables]{Subsetting structables}\label{sec:subsettingstructables}

Structables work in a similar way, but take into account the
hierarchical structure imposed by the ``flattened'' format, and also
distinguish explicitely between subsetting levels and subsetting
tables. In the following example, compare the different effects of
applying the \code{[} and \code{[[} operators to the structable: %]]

<<subset4>>=
hec <- structable(Eye ~ Sex + Hair, data = HairEyeColor)
hec
hec["Male",]
hec[["Male",]]
@ 

\noindent The first form keeps the dimensionality, whereas the second
conditions on the ``\code{Male}'' level and returns the corresponding
subtable. The following does this twice, once for \code{Sex}, and once
for \code{Hair} (restricted to the \code{Male} level):

<<subset5>>=
hec[[c("Male", "Brown"),]]
@ 

\subsection[Subsetting data frames]{Subsetting data frames}\label{sec:subsettingdf}

Data available in data frames (frequency or case form) can also be
subsetted, either by using indexes on the rows and/or columns, or,
more conveniently, by applying the \func{subset} function. The
following statement will extract the \code{Treatment} and
\code{Improved} variables for all female patients older than 68:

<<subset6>>=
rows <- Arthritis$Sex == "Female" & Arthritis$Age > 68
cols <- c("Treatment", "Improved")
Arthritis[rows, cols]
@ 

\noindent Note the use of the single \code{\&} for the logical
expression selecting the rows. The same result can be achieved more
conveniently using the \func{subset} function, first taking the data
set, followed by an expression for selecting the rows (evaluated in
the context of the data frame), and then an expression for selecting
the columns:

<<subset7>>=
subset(Arthritis, Sex == "Female" & Age > 68, 
       select = c(Treatment, Improved))
@ 

\noindent Note the non-standard evaluation of \code{c(Treatment,
  Improved)}: the meaning of \func{c} is not ``combine the two columns into a single
vector'', but ``select both from the data frame''. Likewise, columns
can be removed using \code{-} on column names, which is not possible
using standard indexing in matrices or data frames:

<<>>=
subset(Arthritis, Sex == "Female" & Age > 68, 
       select = -c(Age, ID))
@ 

\section[Collapsing tables]{Collapsing tables}\label{sec:collapsetables}

\subsection[Collapsing over table factors]{Collapsing over table factors: \func{aggregate}, \func{margin.table} and \func{apply}}\label{sec:collapse}

It sometimes happens that we have a data set with more variables or factors than
we want to analyse, or else, having done some initial analyses, we decide that
certain factors are not important, and so should be excluded from graphic displays
by collapsing (summing) over them.  For example, mosaic plots and fourfold displays
are often simpler to construct from versions of the data collapsed over
the factors which are not shown in the plots.

The appropriate tools to use again depend on
the form in which the data are represented---a case-form data frame, a
frequency-form data frame (\func{aggregate}), or a table-form array or
table object (\func{margin.table} or \func{apply}).

When the data are in frequency form, and we want to produce another
frequency data frame, \func{aggregate} is a handy tool, using
the argument \code{FUN = sum} to sum the frequency variable over the
factors \emph{not} mentioned in the formula.

\begin{Example}[dayton1]{Dayton survey}
The data frame \data{DaytonSurvey} in the \pkg{vcdExtra} package represents a
$2^5$ table giving the frequencies of reported use (``ever used?'') of
alcohol, cigarettes and marijuana in a sample of 2276 high school seniors,
also classified by sex and race.

<<dayton1>>=
data("DaytonSurvey", package = "vcdExtra")
str(DaytonSurvey)
head(DaytonSurvey)
@

To focus on the associations among the
substances, we want to collapse over sex and race. The right-hand side of the formula
used in the call to \func{aggregate} gives the factors to be retained in the
new frequency data frame, \code{Dayton_ACM_df}.  The left-hand side is
the frequency variable (\code{Freq}), and we aggregate using the
\code{FUN = sum}.

<<dayton2>>=
# data in frequency form: collapse over sex and race
Dayton_ACM_df <- aggregate(Freq ~ cigarette + alcohol + marijuana,
                           data = DaytonSurvey, FUN = sum)
Dayton_ACM_df
@
\end{Example}

When the data are in table form, and we want to produce another
table, \func{apply} with \code{FUN = sum} can be used in a similar way
to sum the table over dimensions not mentioned in the \code{MARGIN}
argument.  \func{margin.table} is just a wrapper for \func{apply}
using the \func{sum} function.


\begin{Example}[dayton2]{Dayton survey}
To illustrate, we first convert the \data{DaytonSurvey} to a 5-way
table using \func{xtabs}, giving \code{Dayton_tab}.

<<dayton3>>=
# convert to table form
Dayton_tab <- xtabs(Freq ~ cigarette + alcohol + marijuana + sex + race,
                    data = DaytonSurvey)
structable(cigarette + alcohol + marijuana ~ sex + race, 
           data = Dayton_tab)
@
Then, use \func{apply} on \code{Dayton_tab} to give the
3-way table \code{Dayton_ACM_tab} summed over sex and race.
The elements in this new table are the column sums for
\code{Dayton.tab} shown by \func{structable} just above.

<<dayton4>>=
# collapse over sex and race
Dayton_ACM_tab <- apply(Dayton_tab, MARGIN = 1:3, FUN = sum)
Dayton_ACM_tab <- margin.table(Dayton_tab, 1:3)   # same result
structable(cigarette + alcohol ~ marijuana, data = Dayton_ACM_tab)
@
\end{Example}
\noindent (Note that \func{structable} would do the collapsing job for
us anyway.)

%\TODO{DM: plyr seems too much here -> remove?}

Many of these operations can be performed using the \verb|**ply()| functions
in the \pkg{plyr} package.
For example, with the data in a frequency form data frame, use \func{ddply}
to collapse over unmentioned factors, and \func{summarise}%
as the function to be applied to each piece.
<<dayton5, eval=FALSE>>=
library(plyr)
Dayton_ACM_df <- ddply(DaytonSurvey, .(cigarette, alcohol, marijuana),
                       summarise, Freq = sum(Freq))
@

\subsection[Collapsing table levels]{Collapsing table levels: \func{collapse.table}}\label{sec:collapse-levels}

A related problem arises when we have a table or array and for some purpose
we want to reduce the number of levels of some factors by summing subsets
of the frequencies.  For example, we may have initially coded Age in 10-year
intervals, and decide that, either for analysis or display purposes, we
want to reduce Age to 20-year intervals.  The \func{collapse.table} function
in \pkg{vcdExtra} was designed for this purpose.

\begin{Example}[collapse-cat]{Collapsing categories}
Create a 3-way table, and collapse Age from 10-year to 20-year intervals
and Education from three levels to two.
To illustrate, we first generate a $2 \times 6 \times 3$ table of random counts from a
Poisson distribution with mean of 100, with factors \var{sex}, \var{age}
and \var{education}.
<<collapse1>>=
# create some sample data in frequency form
set.seed(12345)   # reproducibility
sex <- c("Male", "Female")
age <- c("10-19", "20-29",  "30-39", "40-49", "50-59", "60-69")
education <- c("low", "med", "high")
dat <- expand.grid(sex = sex, age = age, education = education)
counts <- rpois(36, 100)   # random Poisson cell frequencies
dat <- cbind(dat, counts)
# make it into a 3-way table
tab1 <- xtabs(counts ~ sex + age + education, data = dat)
structable(tab1)
@
Now collapse \code{age} to 20-year intervals, and \code{education}
to 2 levels. In the arguments to \func{collapse.table}, levels of \code{age} and \code{education}
given the same label are summed in the resulting smaller table.
<<collapse2>>=
# collapse age to 3 levels, education to 2 levels
tab2 <- collapse.table(tab1,
         age = c("10-29", "10-29",  "30-49", "30-49", "50-69", "50-69"),
         education = c("<high", "<high", "high"))
structable(tab2)
@
\end{Example}

%\DONE{DM: Add section on subsetting tables using \func{subset}, and the
%  \code{[} and \code{[[} methods for tables and structables. These % ]]]
%skills are required in some examples.}

\section{Converting among frequency tables and data frames}\label{sec:convert}

As we've seen, a given contingency table can be represented
equivalently in case form, frequency form and table form.
However, some \R functions were designed for one particular representation.
\tabref{tab:convert} gives an overview of some handy tools (with
sketched usage) for converting from one form to another, discussed below.

\begin{table}[htb]
 \caption{Tools for converting among different forms for categorical data}\label{tab:convert}
 \newsavebox{\adfxtabs}
 \savebox{\adfxtabs}{\begin{tabular}{ll} \code{Z <- xtabs(\~{ } A + B)} \\ \code{as.data.frame(Z)} \\ \end{tabular}}
 \begin{center}
   \begin{tabular}{l|lll}
  \hline
                 & \multicolumn{3}{c}{\textbf{To this}} \\
	\textbf{From this}      &     Case form         & Frequency form             &  Table form \\
	\hline
  Case form      &  ---                   & \usebox{\adfxtabs}  &  \verb|table(A, B)|  \\
%	Case form      &                        & {\small\verb|as.data.frame(xtabs(~A+B))|}        &  \verb|table(A,B)|  \\
	Frequency form &  \verb|expand.dft(X)|  & ---   & \verb|xtabs(count ~ A + B)|\\
	Table form     &  \verb|expand.dft(X)|  & \verb|as.data.frame(X)|   &  ---     \\
	\hline
   \end{tabular}
 \end{center}
\end{table}

\subsection{Table form to frequency form}
A contingency table in table form (an object of class \class{table}) can be converted
to a data frame in frequency form with \func{as.data.frame}.%
\footnote{
Because \R is object-oriented, this is actually a short-hand for
the function \func{as.data.frame.table}, which is automatically selected
for objects of class \class{table}.}
The resulting
data frame contains columns
representing the classifying factors and the table entries (as a column named by
the \code{responseName} argument, defaulting to \code{Freq}).  The function
\func{as.data.frame} is the inverse of \func{xtabs}, which converts a data frame to a table.

\begin{Example}[GSS-convert]{General social survey}
Convert the \code{GSStab} object in table form to a data.frame in frequency form.
By default, the frequency variable is named \code{Freq}, and the variables
\code{sex} and \code{party} are made factors.
<<convert-ex1>>=
as.data.frame(GSStab)
@
\end{Example}

In addition, there are situations where numeric table variables are represented as
factors, but you need to
convert them to numerics for calculation purposes.

\begin{Example}[horse.df]{Death by horse kick}

For example, we might want to calculate the weighted mean of \code{nDeaths}
in the \data{HorseKicks} data.
Using \func{as.data.frame} won't work here, because the variable \code{nDeaths}
becomes a factor.

<<horse.df1>>=
str(as.data.frame(HorseKicks))
@
One solution is to use \func{data.frame} directly and \func{as.numeric}
to coerce the table names to numbers.
<<horse.df2>>=
horse.df <- data.frame(nDeaths = as.numeric(names(HorseKicks)),
                       Freq = as.vector(HorseKicks))
str(horse.df)
horse.df
@
Then, \func{weighted.mean} works as we would like:
<<horse.df3>>=
weighted.mean(horse.df$nDeaths, weights=horse.df$Freq)
@
\end{Example}

\subsection{Case form to table form}
Going the other way, we use \func{table} to convert from case form to table form.

\begin{Example}[Arth-convert]{Arthritis treatment}
Convert the \data{Arthritis} data in case form to a 3-way table of
\code{Treatment} $\times$ \code{Sex} $\times$ \code{Improved}.
We select the desired columns with their names, but could also use column
numbers, e.g., \newline \code{table(Arthritis[,c(2,3,5)])}. 
%\TODO{PC: \newline forced above to avoid prevent hanging text. Isolated here, so it should 
% be fine}
%Note the use of \func{with} to avoid having to use \code{Arthritis\$Treatment} etc. within %the call to \func{table}.%
<<convert-ex2>>=
Art.tab <- table(Arthritis[,c("Treatment", "Sex", "Improved")])
str(Art.tab)
ftable(Art.tab)
@
\end{Example}

\subsection{Table form to case form}
There may also be times that you will need an equivalent case form data frame
with factors  representing the table variables
rather than the frequency  table.
For example, the \func{mca} function in package \pkg{MASS} (for
multiple correspondence analysis)
only operates on data in this format.
The function \func{expand.dft}%
\footnote{
The original code for this function was provided by Marc Schwarz on the R-Help
mailing list.
}
in \pkg{vcdExtra}
does this, converting a table into a case form.

\begin{Example}[Arth-convert2]{Arthritis treatment}
Convert the \data{Arthritis} data in table form (\code{Art.tab}) back to a \code{data.frame}
in case form, with factors
\code{Treatment}, \code{Sex} and \code{Improved}.
<<convert-ex3,size="footnotesize">>=
library(vcdExtra)
Art.df <- expand.dft(Art.tab)
str(Art.df)
@
\end{Example}

\subsection{Publishing tables to \LaTeX\ or HTML}
OK, you've read your data into \R, done some analysis, and now want to
include some tables in a \LaTeX\ document or in a web page in HTML format.
Formatting tables for these purposes is often tedious and error-prone.

There are a great many packages in \R that provide for nicely formatted,
publishable tables for a wide variety of purposes; indeed, most of the tables
in this book are generated using these tools.
See \citet{Leifeld:2013:JSS} for description of the \Rpackage{texreg}
and a comparison with some of the other packages.

Here, we simply illustrate the \Rpackage{xtable}, which, along with
capabilities for statistical model summaries, time-series data, and
so forth, has a \code{xtable.table} method for one-way and two-way
table objects.

The \data{HorseKicks} data is a small one-way frequency table
described in \exref{ex:horsekick1} and contains the frequencies
of 0, 1, 2, 3, 4 deaths per corps-year by horse-kick among soldiers in 20 corps in
the Prussian army.
<<xtable1>>=
data("HorseKicks", package = "vcd")
HorseKicks
@
By default, \func{xtable} formats this in \LaTeX\ as a vertical table,
and prints the \LaTeX\ markup to the \R console.  This output is shown
below. 
%(without the usual \code{\#\#} comment used to indicate \R output).
<<xtable2, comment=NA>>=
library(xtable)
xtable(HorseKicks)
@
When this is rendered in a \LaTeX\ document, the result of \func{xtable}
appears as shown in the table below.
<<xtable3, results='asis'>>=
xtable(HorseKicks)
@

The table above isn't quite right, because the column label ``nDeaths''
belongs to the first column, and the second column should be labeled ``Freq''.
To correct that, we convert the \data{HorseKicks} table to a data frame
(see \secref{sec:convert} for details), add the appropriate \code{colnames},
and use the \code{print.xtable} method to supply some other options.
<<xtable4, results='asis', size='small'>>=
tab <- as.data.frame(HorseKicks)
colnames(tab) <- c("nDeaths", "Freq")
print(xtable(tab), include.rownames = FALSE, 
      include.colnames = TRUE)
@
\noindent There are many more options to control the \LaTeX\ details and
polish the appearance of the table; see \help{xtable} and
\code{vignette("xtableGallery", package = "xtable")}

% \DONE{DM: The code looks quite complicated and the result is not
%   satisfying (no separator between header and table) - maybe too confusing?}

Finally, in \chref{ch:discrete}, we display a number of similar one-way
frequency tables in a transposed form to save display space.
\tabref{tab:horsetab} is the finished version we show there.
The code below uses the following techniques:
(a) \func{addmargins} is used to show the sum of all the frequency values;
(b) \func{t} transposes the data frame to have 2 rows;
(c) \func{rownames} assigns the labels we want for the rows;
(d) using the \code{caption} argument provides a table caption, and a numbered
table in \LaTeX;
(d) column alignment (\code{"r"} or \code{"l"}) for the table columns
is computed as a character string used for the \code{align} argument.
<<xtable5, results='asis', size='small'>>=
horsetab <- t(as.data.frame(addmargins(HorseKicks)))
rownames(horsetab) <- c( "Number of deaths", "Frequency" )
horsetab <- xtable(horsetab, digits = 0,
     caption = "von Bortkiewicz's data on deaths by horse kicks",
     align = paste0("l|", paste(rep("r", ncol(horsetab)), 
                                collapse = ""))
     )
print(horsetab, include.colnames = FALSE)
@

For use in a web page, blog, or Word document, you can use \code{type="HTML"} in the
call to \func{print} for \class{xtable} objects.
%\DONE{DM: also show HTML version? --- MF: added note above}


\section{A complex example: TV viewing data\hard}\label{sec:working-complex}

If you have followed so far, congratulations! You are ready for a more complicated example
that puts together a variety of the skills developed in this chapter:
\begin{seriate}
  \item reading raw data,
  \item creating tables,
  \item assigning level names to factors and
  \item collapsing levels or variables for use in analysis.
\end{seriate}

\ixeon{TV viewing data}
For an illustration of these steps,
we use the dataset \code{tv.dat}, supplied with
the initial implementation of
mosaic displays in \R by Jay Emerson.
In turn, they were derived from an early, compelling example of mosaic displays
\citep{HartiganKleiner:84},
that illustrated the method with data on a large sample of TV viewers
whose behavior had been recorded for the Neilsen ratings.
This data set contains sample television audience data from Neilsen
Media Research for the week starting November 6, 1995.


The data file, \code{tv.dat} is stored in frequency form
as a file with 825 rows and 5 columns.  There is no header line
in the file, so when we use \func{read.table} below, the variables
will be named \code{V1} -- \code{V5}.  This data represents
 a 4-way table of size
$5 \times 11 \times 5 \times 3 = 825$ where the table variables
are \code{V1} -- \code{V4}, and the cell frequency is read
as \code{V5}.

%% should use \begin{description} ... here
\begin{flushleft}
The table variables are:\\
~~~\code{V1}--- values 1:5 correspond to the days Monday--Friday;\\
~~~\code{V2}--- values 1:11 correspond to the quarter hour times 8:00PM through 10:30PM;\\
~~~\code{V3}--- values 1:5 correspond to ABC, CBS, NBC, Fox, and non-network choices;\\
~~~\code{V4}--- values 1:3 correspond to transition states: turn the television Off, Switch channels,  or Persist in viewing the current channel.
\end{flushleft}

\subsection{Creating data frames and arrays}
The file \code{tv.dat} is stored in the \code{doc/extdata} directory
of \pkg{vcdExtra}; it can be read as follows:
<<tv1>>=
tv_data <- read.table(system.file("doc", "extdata", "tv.dat", 
                                  package = "vcdExtra"))
str(tv_data)
head(tv_data, 5)
@
To read such data from a local file, just use \func{read.table} in this form:
<<tv2,eval=FALSE>>=
tv_data <- read.table("C:/R/data/tv.dat")
@
or, to select the path using the file chooser tool,
<<tv2bb,eval=FALSE>>=
tv_data <- read.table(file.choose())
@

We could use this data in frequency form for analysis by renaming the variables,
and converting the integer-coded factors \code{V1} -- \code{V4} to \R factors.
The lines below use the function \func{within} to avoid having to use
\verb|TV.dat$Day <- factor(TV.dat$Day)| etc., and only supplies labels for the
first variable.
<<TV-df>>=
TV_df <- tv_data
colnames(TV_df) <- c("Day", "Time", "Network", "State", "Freq")
TV_df <- within(TV_df, {
             Day <- factor(Day, 
                           labels = c("Mon", "Tue", "Wed", "Thu", "Fri"))
             Time <- factor(Time)
             Network <- factor(Network)
             State <- factor(State) 
	 })
@

Alternatively, we could just reshape the frequency column
(\code{V5} or \code{tv_data[,5]}) into
a 4-way array.
In the lines below, we rely on the facts that the
(a) the table is complete---there are no missing cells,
so \code{nrow(tv_data)}~=~\Sexpr{nrow(tv_data)};
(b) the observations are ordered so that \code{V1} varies most rapidly and
\code{V4} most slowly.  From this, we can just extract the frequency column
and reshape it into an array using the \code{dim} argument.
The level names are assigned to \code{dimnames(TV)}
and the variable names to \code{names(dimnames(TV))}.
<<tv2a>>=
TV <- array(tv_data[,5], dim = c(5, 11, 5, 3))
dimnames(TV) <- 
    list(c("Mon", "Tue", "Wed", "Thu", "Fri"),
         c("8:00", "8:15", "8:30", "8:45", "9:00", "9:15", 
           "9:30", "9:45", "10:00", "10:15", "10:30"),
         c("ABC", "CBS", "NBC", "Fox", "Other"),
         c("Off", "Switch", "Persist"))
names(dimnames(TV)) <- c("Day", "Time", "Network", "State")
@

More generally (even if there are missing cells), we can
use \func{xtabs} to do the cross-tabulation, using \code{V5} as the
frequency variable.  Here's how to do this same operation with \func{xtabs}:
<<tv2b,eval=FALSE>>=
TV <- xtabs(V5 ~ ., data = tv_data)
dimnames(TV) <- 
    list(Day = c("Mon", "Tue", "Wed", "Thu", "Fri"),
         Time = c("8:00", "8:15", "8:30", "8:45", "9:00", "9:15", 
                  "9:30", "9:45", "10:00", "10:15", "10:30"),
         Network = c("ABC", "CBS", "NBC", "Fox", "Other"),
         State = c("Off", "Switch", "Persist"))
@
\noindent Note that in the lines above, the variable names are assigned directly
as the names of the elements in the \code{dimnames} list.

\subsection{Subsetting and collapsing}
For many purposes,
the 4-way table \code{TV}
is too large and awkward to work with. Among the networks,
Fox and Other occur infrequently, so we will remove them.
We can also cut it down to a 3-way table by considering only viewers who persist
with the current station.%
\footnote{This relies on the fact that indexing
an array drops dimensions of length 1 by default,
using the argument \code{drop = TRUE};
the result is coerced to the lowest possible dimension.
}

<<tv3>>=
TV <- TV[,,1:3,]     # keep only ABC, CBS, NBC
TV <- TV[,,,3]       # keep only Persist -- now a 3 way table
structable(TV)
@

Finally, for some purposes, we might also want to collapse the 11 \code{Time}'s into a smaller number.
Here, we use \func{collapse.table} (see \secref{sec:collapse-levels}), which was designed for this purpose.
% Here, we use \func{as.data.frame.table} to convert the table back to a data frame,
%  \func{levels} to re-assign the values of \code{Time},
%  and finally, \func{xtabs} to give a new, collapsed frequency table.

%\DONE{DM: Why not using \func{collapse.table} as introduced before?}
 
% # <<tv4>>=
% # TV_df <- as.data.frame.table(TV)
% # levels(TV_df$Time) <- c(rep("8:00-8:59", 4),
% #                         rep("9:00-9:59", 4), rep("10:00-10:44", 3))
% # TV2 <- xtabs(Freq ~ Day + Time + Network, TV_df)
% # 
% # @

<<tv4>>=
TV2 <- collapse.table(TV, 
                      Time = c(rep("8:00-8:59", 4),
                               rep("9:00-9:59", 4), 
			       rep("10:00-10:44", 3)))
structable(Day ~ Time + Network, TV2)
@

Congratulations! If you followed the operations described above,
you are ready for the material described in the rest of the book.
If not, try working through some of exercises below.

% As a final step and a prelude to what follows, we construct a mosaic
% plot, below (\figref{fig:TV-mosaic}) that focuses on the associations
% between the combinations of \code{Day} and \code{Time} and the
% \code{Network} viewed.  In terms of a \loglin model, this is
% represented by the model formula \verb|~Day:Time + Network|,
% which asserts that \code{Network} is independent of the
% \code{Day:Time} combinations.

% <<TV-mosaic, h=7, w=7, out.width=".75\\textwidth", cap="Mosaic plot for the TV data showing model of joint independence, \\texttt{Day:Time + Network}", scap="Mosaic plot for the TV data", fig.pos='!htb'>>=
% dimnames(TV2)$Time <- c("8", "9", "10")     # re-level for mosaic display
% mosaic(~ Day + Network + Time, data=TV2, expected=~Day:Time + Network,
%          legend=FALSE, gp=shading_Friendly)
% @
% \noindent
% The cells shaded in blue show positive associations (observed frequency $>$ expected) and red shows negative associations.  From this it is easy to read
% how network choice varies with day and
% time. For example, CBS dominates in all time slots on Monday;
% ABC and NBC dominate on Tuesday, particularly in the later time slots;
% Thursday is an NBC day, while on Friday, ABC gets the greatest share.
% \ixeoff{TV viewing data}

% \section{Further reading}\label{sec:ch02-reading}

% If you're new to the \R language but keen to get started with linear modeling or logistic regression in the language, take a look at this \emph{Introduction to R},
% \url{http://data.princeton.edu/R/introducingR.pdf},
% by Germ\'an Rodr\'iguez.

\section{Lab exercises}\label{sec:ch02-exercises}
<<exercises02, child="ch02/exercises.Rnw">>=
@

%\TODO{Cleanup some local variables}
<<cleanup2, echo=FALSE>>=
.locals$ch02 <- setdiff(ls(), .globals)
remove(list=.locals$ch02[sapply(.locals$ch02,function(n){!is.function(get(n))})])
.pkgs$ch02 <- setdiff(.packages(), .base.pkgs)

@

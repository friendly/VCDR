---
title: "DDAR: Solutions and Hints for Exercises"
date: "`r Sys.Date()`"
output: word_document
---

```{r nomessages, echo = FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)
```

```{r setup, echo=FALSE}
library(vcdExtra)
options(digits=4)
par(mar=c(5,4,1,1)+.1)
```


## Chapter 1

These exercises are all conceptual. There are no hints or solutions.

## Chapter 2

### Exercise 2.2

### Exercise 2.3

The data set `DanishWelfare` in `vcd` gives a 4-way, 3 x 4 x 3 x 5 table as a data frame in frequency form, containing the variable Freq and four factors, Alcohol, Income, Status and Urban. The variable Alcohol can be considered as the response variable, and the others as possible predictors.

a. Find the total number of cases represented in this table.

This is a data set in the form of a frequency data.frame, so sum the `Freq` variable
```{r ex2.3.a}
data("DanishWelfare", package="vcd")
sum(DanishWelfare$Freq)
```

b. In this form, the variables Alcohol and Income should arguably be considered ordered factors. Change them to make them ordered.

Use `ordered()` or `as.ordered()` on the factor variable.  `str()` will then show them as `Ord.factor`.
```{r ex2.3.b}
levels(DanishWelfare$Alcohol)
DanishWelfare$Alcohol <- as.ordered(DanishWelfare$Alcohol)
DanishWelfare$Income <- as.ordered(DanishWelfare$Income)
str(DanishWelfare)
```

c.  Convert this data frame to table form, `DanishWelfare.tab`, a 4-way array containing the frequencies with appropriate variable names and level names. 

Use `xtabs()` with `Freq` as the response.

```{r ex2.3.c}
DanishWelfare.tab <-xtabs(Freq ~ ., data = DanishWelfare)
str(DanishWelfare.tab)
```

d.  The variable Urban has 5 categories. Find the total frequencies in each of these. How would you collapse the table to have only two categories, City, Non-city?

`margin.table()` handles the first part; `collapse.table()` is designed for the second part. It is arguable whether
`SubCopenhagen` should be considered City or NonCity.
```{r ex2.3.d}
margin.table(DanishWelfare.tab, 4)
DW2 <- vcdExtra::collapse.table(DanishWelfare.tab, Urban=c("City","NonCity","City","City","NonCity"))
head(ftable(DW2))
```

## Chapter 3

# Exercise 3.6 

Mosteller and Wallace (1963, Table 2.4) give the frequencies, $n_k$, of counts $k =
0, 1, \dots$ of other selected marker words in 247 blocks of text known to have been written by Alexander Hamilton. The data below show the occurrences of the word *upon*, that Hamilton used much
more than did James Madison.

a. Read these data into R and construct a one-way table of frequencies of counts or a matrix or
data frame with frequencies in the first column and the corresponding counts in the second
column, suitable for use with `goodfit()`.

`goodfit()` requires its first argument to be either a one-way table (from `xtabs()`),
or a data.frame with frequencies in the first column and the corresponding counts in the second column.  Both of the following forms will work.
```{r upon1}
count <- 0:5
Freq <- c(129, 83, 20, 9, 5, 1)
sum(Freq)  # check N

(Upon <- data.frame(Freq, count))             # as a data.frame
(Upon.tab <- xtabs(Freq ~ count, data=Upon))  # one-way table

```


b. Fit and plot the Poisson model for these frequencies.
```{r upon2}
(up0 <- goodfit(Upon, type="poisson"))
summary(up0)
plot(up0)
```

c. Fit and plot the negative binomial model for these frequencies.
```{r}
(up1 <- goodfit(Upon, type="nbinomial"))
summary(up1)
plot(up1)
```

d. What do you conclude?


```{r child="ex04.Rmd"}

```



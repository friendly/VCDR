\chapter{Correspondence analysis} \label{ch:corresp}
\input{ch5/vtoc}
\ixon{correspondence analysis}
\begin{quote}
{\Large
Correspondence analysis provides visualizations of associations in a two-way \ctab\
in a small number of dimensions.
Multiple correspondence analysis extends this technique to \nway\
tables.  Other grahical methods, including mosaic matrices and biplots
provide complementary views of \loglin\ models for two-way and \nway\
\ctab{}s.
}
\end{quote}
\minitoc
\clearpage

\section{Introduction}
\epigraph{Whenever a large sample of
chaotic elements
are taken in hand and marshaled in the order of their magnitude, an
unsuspected and most beautiful form of regularity proves to have been
latent all along.}
{Sir Francis Galton (1822-1911)}
Correspondence analysis (CA) is an exploratory technique which displays
the row and column categories in a two-way contingency table as points
in a graph, so that the positions of the points represent the
associations in the table.
Mathematically, correspondence analysis is related to the biplot,
to canonical correlation,
and to principal components analysis
(see \SSSGref{8,7, 9.4, 10.3}).
This technique finds
scores for the row and column categories on a small number of
dimensions which account for the greatest proportion of the
\(\chi^2\) for association between the row and column categories,
just as principal components account for maximum variance.
These scores provide a quantification of the categories,
and have the property that they maximize the correlation
between the row and column variables.   For
graphical display two or three dimensions are typically used to give
a reduced rank approximation to the data.

Correspondence analysis has a very large, multi-national literature and
was rediscovered several times in different fields and different countries.   The method, in slightly different forms, is also
discussed under the names
\boldital{dual scaling}, \boldital{optimal scaling},
\boldital{reciprocal averaging},
\boldital{homogeneity analysis},
and \boldital{canonical analysis of
categorical data}.

See \citet{Greenacre:84}, \citet{Nishisato:80},
or \citet{Gifi:81,Lebart-etal:77,Lebart-etal:84}
for a detailed treatment of the method and its applications.
\citet{GreenacreHastie:87} provide an excellent discussion of
the geometric interpretation,
while \citet{HeijdenLeeuw:85} and \citet{Heijden-etal:89}
develop some of the relations between correspondence analysis
and log-linear methods for three-way and larger tables.
Correspondence analysis is usually carried out in an exploratory,
graphical way; however,
\citet{Goodman:81,Goodman:85,Goodman:86} has developed related inferential models, the $RC$ model and
the canonical correlation model, with close links to \CA.

For a two-way table the scores for the row categories, namely
\(\mat{X} = \{x_{im}\}\), and column categories, \(\mat{Y} = \{y_{jm}\}\), on dimension \(m = 1,
\dots , \,  M\) are derived from a (generalized) singular value decomposition of
residuals from independence, expressed as \(d_{ij} /  \sqrt n\), to
account for the largest proportion of the \(\chi^2\) in a small
number of dimensions.  This decomposition may be expressed as
\ix{singular value decomposition}
%
\begin{equation} \label{eq:cadij}
  \frac{d_{ij}}{\sqrt{n}} = 
  \frac{n_{ij} - m_{ij}} {\sqrt {n \,  m_{ij}}} =
  \sum_{m=1}^M  \lambda_m \,  x_{im} \,  y_{jm}
  \comma
\end{equation}
where \(\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_M\), and \(M
=  \min ( I-1 , \,  J-1 )\).  In \(M\) dimensions, the decomposition
\eqref{eq:cadij} is exact.
For example, an \(I \times 3\) table can be depicted exactly
in two dimensions when $I \ge 3$.  A rank-\(d\) approximation in \(d\) dimensions is
obtained from the first \(d\) terms on the right side of \eqref{eq:cadij};
the proportion of the Pearson \(\chi^2\) accounted for by this approximation is
\begin{equation*}
 n \,  \sum_m^d { \,  \lambda_m^2 } \big/  \chi^2
 \period
\end{equation*}
The quantity $\chi^2 /n = \sum_i \sum_j d_{ij}^2  / n$ is called
the total \glossterm{inertia} and is identical to the measure of
association known as Pearson's mean-square contingency, the
square of the $\phi$ coefficient.
\ix{$\phi$ coefficient}
\ix{phi coefficient@phi ($\phi$) coefficient}
\ix{mean-square contingency coefficient}

Thus, correspondence analysis is designed to show how the data
deviate from expectation when the row and column variables are
independent, as in the association plot and mosaic display.  However,
the association plot and mosaic display depict every \emph{cell} in
the table, and for large tables it may be difficult to see patterns.
Correspondence analysis shows only row and column \emph{categories} in
the two (or three) dimensions which account for the greatest
proportion of deviation from independence.
The pattern of the associations is inferred from the positions of the
row and column points.

\input{ch5/simple}
\ixon{correspondence analysis!multi-way tables}
\input{ch5/multiway}
\ixon{correspondence analysis!multiple}
\input{ch5/mca}
\ixoff{correspondence analysis!multiple}
\ixoff{correspondence analysis!multi-way tables}
\ixoff{correspondence analysis}
\input{ch5/biplot}

\section{Chapter summary}
\begin{itemize}
\item Correspondence analysis is an exploratory technique, designed to
show the row and column categories in a two- (or three-) dimensional
space.  These graphical displays, and various extensions, provide
ways to interpret the patterns of association and explore visually
the adequacy of certain \loglin\ models.

\item The scores assigned to the categories of each variable are optimal
in several equivalent ways.
Among other properties,
they maximize the (canonical) correlations between the quantified
variables (weighted by cell frequencies), and make the regressions
of each variable on the other most nearly linear, for each CA dimension.

\item Multi-way tables may be analyzed in several ways.
In the ``stacking'' approach, two or more variables may be combined
interactively in the rows and/or columns of an \nway\ table.
Simple CA of the restructured table reveals associations between
the row and column categories of the restructured table,
but hides associations between the variables combined interactively.
Each way of stacking corresponds to a particular \loglin\ model
for the full table.

\item Multiple \CA\ is a generalization of CA to two or more variables
based on representing the data as an indicator matrix.
The usual MCA provides an analysis of the joint, bivariate relations
between all pairs of variables.

\item An extended form of MCA provides a means to display higher-order
associations among multiple categorical variables.
For $2^Q$ tables composed of $Q$ binary variables, this analysis yields
simple geometric relations that may be interpreted in terms of odds ratios.

\item The biplot is a related technique for visualizing the elements of
a data array by points or vectors in a joint display of their row and
column categories.
An application of the biplot to \ctab\ data is described, based on analysis
of log frequency.
This analysis also serves to diagnose patterns of independence and
partial independence in two-way and larger tables.
\end{itemize}
